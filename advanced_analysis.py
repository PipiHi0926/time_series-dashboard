import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from typing import Dict, List, Tuple, Optional
from scipy import stats
from scipy.signal import find_peaks
import warnings
warnings.filterwarnings('ignore')

def level_shift_detection_page():
    """Level Shift æª¢æ¸¬é é¢"""
    st.header("ğŸ”„ Level Shift æª¢æ¸¬åˆ†æ")
    
    if st.session_state.fab_data is None:
        st.warning("âš ï¸ è«‹å…ˆä¸Šå‚³æ•¸æ“šä¸¦é¸æ“‡ FAB")
        st.info("ğŸ’¡ è«‹å…ˆå¾å·¦å´é¸å–®é¸æ“‡ã€ŒKPI å¿«é€Ÿåˆ†æã€è¼‰å…¥æ•¸æ“š")
        return
    
    fab_data = st.session_state.fab_data
    selected_fab = st.session_state.selected_fab
    available_kpis = st.session_state.available_kpis
    
    # é¡¯ç¤ºç•¶å‰é¸æ“‡
    st.info(f"ğŸ­ ç•¶å‰ FAB: **{selected_fab}** | ğŸ“Š ç•¶å‰ KPI: **{st.session_state.selected_kpi}**")
    
    st.subheader(f"ğŸ­ {selected_fab} - Level Shift æª¢æ¸¬")
    
    # åƒæ•¸è¨­å®š
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        selected_kpi = st.selectbox(
            "é¸æ“‡ KPI:",
            options=available_kpis,
            index=available_kpis.index(st.session_state.selected_kpi) if st.session_state.selected_kpi in available_kpis else 0
        )
    
    with col2:
        comparison_window = st.slider("æ¯”è¼ƒçª—å£å¤§å° (å¤©):", 3, 30, 7, 1,
                                    help="å‰å¾Œæ¯”è¼ƒçš„å¤©æ•¸çª—å£")
    
    with col3:
        significance_level = st.slider("é¡¯è‘—æ€§æ°´æº–:", 0.01, 0.10, 0.05, 0.01,
                                     help="çµ±è¨ˆæª¢é©—çš„é¡¯è‘—æ€§æ°´æº–")
    
    with col4:
        min_shift_magnitude = st.number_input("æœ€å°è®ŠåŒ–å¹…åº¦ (%):", 0.0, 50.0, 5.0, 0.5,
                                            help="è¦–ç‚ºLevel Shiftçš„æœ€å°è®ŠåŒ–ç™¾åˆ†æ¯”")
    
    if st.button("ğŸ” åŸ·è¡Œ Level Shift æª¢æ¸¬", type="primary"):
        kpi_data = fab_data[fab_data['KPI'] == selected_kpi].copy()
        kpi_data = kpi_data.sort_values('REPORT_TIME')
        
        if len(kpi_data) < comparison_window * 2:
            st.error(f"âŒ æ•¸æ“šé»ä¸è¶³ï¼Œè‡³å°‘éœ€è¦ {comparison_window * 2} å€‹æ•¸æ“šé»")
            return
        
        # åŸ·è¡Œ Level Shift æª¢æ¸¬
        shift_results = detect_level_shifts(
            kpi_data, comparison_window, significance_level, min_shift_magnitude
        )
        
        # é¡¯ç¤ºçµæœ
        display_level_shift_results(shift_results, kpi_data, selected_kpi, selected_fab)

def trend_momentum_analysis_page():
    """è¶¨å‹¢å‹•é‡åˆ†æé é¢"""
    st.header("ğŸ“ˆ è¶¨å‹¢å‹•é‡åˆ†æ")
    
    if st.session_state.fab_data is None:
        st.warning("âš ï¸ è«‹å…ˆä¸Šå‚³æ•¸æ“šä¸¦é¸æ“‡ FAB")
        st.info("ğŸ’¡ è«‹å…ˆå¾å·¦å´é¸å–®é¸æ“‡ã€ŒKPI å¿«é€Ÿåˆ†æã€è¼‰å…¥æ•¸æ“š")
        return
    
    fab_data = st.session_state.fab_data
    selected_fab = st.session_state.selected_fab
    available_kpis = st.session_state.available_kpis
    
    # é¡¯ç¤ºç•¶å‰é¸æ“‡
    st.info(f"ğŸ­ ç•¶å‰ FAB: **{selected_fab}** | ğŸ“Š ç•¶å‰ KPI: **{st.session_state.selected_kpi}**")
    
    st.subheader(f"ğŸ­ {selected_fab} - è¶¨å‹¢å‹•é‡åˆ†æ")
    
    # åƒæ•¸è¨­å®š
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        selected_kpi = st.selectbox(
            "é¸æ“‡ KPI:",
            options=available_kpis,
            index=available_kpis.index(st.session_state.selected_kpi) if st.session_state.selected_kpi in available_kpis else 0
        )
    
    with col2:
        short_window = st.slider("çŸ­æœŸçª—å£ (å¤©):", 3, 14, 7, 1,
                               help="çŸ­æœŸè¶¨å‹¢è¨ˆç®—çª—å£")
    
    with col3:
        long_window = st.slider("é•·æœŸçª—å£ (å¤©):", 14, 90, 28, 1,
                              help="é•·æœŸè¶¨å‹¢è¨ˆç®—çª—å£")
    
    with col4:
        momentum_threshold = st.slider("å‹•é‡é–¾å€¼:", 0.1, 2.0, 0.5, 0.1,
                                     help="åˆ¤æ–·é¡¯è‘—è¶¨å‹¢è®ŠåŒ–çš„é–¾å€¼")
    
    # åˆ†æé¸é …
    analysis_options = st.multiselect(
        "é¸æ“‡åˆ†ææ–¹æ³•:",
        ["è¶¨å‹¢å‹•é‡åˆ†æ", "é€£çºŒè¶¨å‹¢æª¢æ¸¬", "åŠ é€Ÿåº¦åˆ†æ", "è¶¨å‹¢å¼·åº¦è©•ä¼°"],
        default=["è¶¨å‹¢å‹•é‡åˆ†æ", "é€£çºŒè¶¨å‹¢æª¢æ¸¬"]
    )
    
    if st.button("ğŸ” åŸ·è¡Œè¶¨å‹¢å‹•é‡åˆ†æ", type="primary"):
        kpi_data = fab_data[fab_data['KPI'] == selected_kpi].copy()
        kpi_data = kpi_data.sort_values('REPORT_TIME')
        
        if len(kpi_data) < long_window + 5:
            st.error(f"âŒ æ•¸æ“šé»ä¸è¶³ï¼Œè‡³å°‘éœ€è¦ {long_window + 5} å€‹æ•¸æ“šé»")
            return
        
        # åŸ·è¡Œè¶¨å‹¢å‹•é‡åˆ†æ
        momentum_results = analyze_trend_momentum(
            kpi_data, short_window, long_window, momentum_threshold, analysis_options
        )
        
        # é¡¯ç¤ºçµæœ
        display_momentum_results(momentum_results, kpi_data, selected_kpi, selected_fab)

def detect_level_shifts(kpi_data: pd.DataFrame, window: int, 
                       significance: float, min_magnitude: float) -> Dict:
    """æª¢æ¸¬ Level Shift"""
    values = kpi_data['VALUE'].values
    dates = kpi_data['REPORT_TIME'].values
    
    shifts = []
    shift_explanations = []
    
    for i in range(window, len(values) - window):
        # å‰å¾Œçª—å£æ•¸æ“š
        before = values[i-window:i]
        after = values[i:i+window]
        
        # çµ±è¨ˆæª¢é©—
        t_stat, p_value = stats.ttest_ind(before, after)
        
        # è¨ˆç®—è®ŠåŒ–å¹…åº¦
        before_mean = np.mean(before)
        after_mean = np.mean(after)
        change_pct = abs((after_mean - before_mean) / before_mean) * 100
        
        # åˆ¤æ–·æ˜¯å¦ç‚ºé¡¯è‘— Level Shift
        if p_value < significance and change_pct >= min_magnitude:
            shift_type = "ä¸Šå‡" if after_mean > before_mean else "ä¸‹é™"
            
            shifts.append({
                'index': i,
                'date': dates[i],
                'before_mean': before_mean,
                'after_mean': after_mean,
                'change_pct': change_pct,
                'change_direction': shift_type,
                't_stat': t_stat,
                'p_value': p_value,
                'before_std': np.std(before),
                'after_std': np.std(after)
            })
            
            # ç”Ÿæˆè§£é‡‹
            explanation = generate_level_shift_explanation(
                before_mean, after_mean, change_pct, shift_type, p_value, window
            )
            shift_explanations.append(explanation)
    
    return {
        'shifts': shifts,
        'explanations': shift_explanations,
        'values': values,
        'dates': dates,
        'window': window
    }

def analyze_trend_momentum(kpi_data: pd.DataFrame, short_window: int, 
                         long_window: int, threshold: float, 
                         analysis_options: List[str]) -> Dict:
    """åˆ†æè¶¨å‹¢å‹•é‡"""
    values = kpi_data['VALUE'].values
    dates = kpi_data['REPORT_TIME'].values
    
    results = {
        'values': values,
        'dates': dates,
        'short_window': short_window,
        'long_window': long_window
    }
    
    if "è¶¨å‹¢å‹•é‡åˆ†æ" in analysis_options:
        momentum_data = calculate_trend_momentum(values, short_window, long_window)
        results['momentum'] = momentum_data
    
    if "é€£çºŒè¶¨å‹¢æª¢æ¸¬" in analysis_options:
        continuous_trends = detect_continuous_trends(values, dates, short_window, threshold)
        results['continuous_trends'] = continuous_trends
    
    if "åŠ é€Ÿåº¦åˆ†æ" in analysis_options:
        acceleration_data = calculate_trend_acceleration(values, short_window)
        results['acceleration'] = acceleration_data
    
    if "è¶¨å‹¢å¼·åº¦è©•ä¼°" in analysis_options:
        strength_data = evaluate_trend_strength(values, short_window, long_window)
        results['strength'] = strength_data
    
    return results

def calculate_trend_momentum(values: np.ndarray, short_window: int, long_window: int) -> Dict:
    """è¨ˆç®—è¶¨å‹¢å‹•é‡"""
    short_trends = []
    long_trends = []
    momentum_signals = []
    
    # è¨ˆç®—çŸ­æœŸå’Œé•·æœŸè¶¨å‹¢
    for i in range(long_window, len(values)):
        # çŸ­æœŸè¶¨å‹¢ (æ–œç‡)
        short_data = values[i-short_window:i]
        short_x = np.arange(len(short_data))
        short_slope = np.polyfit(short_x, short_data, 1)[0]
        short_trends.append(short_slope)
        
        # é•·æœŸè¶¨å‹¢ (æ–œç‡)
        long_data = values[i-long_window:i]
        long_x = np.arange(len(long_data))
        long_slope = np.polyfit(long_x, long_data, 1)[0]
        long_trends.append(long_slope)
        
        # å‹•é‡ä¿¡è™Ÿ (çŸ­æœŸè¶¨å‹¢ - é•·æœŸè¶¨å‹¢)
        momentum = short_slope - long_slope
        momentum_signals.append(momentum)
    
    return {
        'short_trends': np.array(short_trends),
        'long_trends': np.array(long_trends),
        'momentum_signals': np.array(momentum_signals),
        'start_index': long_window
    }

def detect_continuous_trends(values: np.ndarray, dates: np.ndarray, 
                           window: int, threshold: float) -> Dict:
    """æª¢æ¸¬é€£çºŒè¶¨å‹¢"""
    trends = []
    continuous_periods = []
    
    # è¨ˆç®—æ»‘å‹•è¶¨å‹¢
    for i in range(window, len(values)):
        data = values[i-window:i]
        x = np.arange(len(data))
        slope, intercept, r_value, p_value, std_err = stats.linregress(x, data)
        
        trends.append({
            'index': i,
            'slope': slope,
            'r_value': r_value,
            'p_value': p_value,
            'trend_strength': abs(slope) * abs(r_value)
        })
    
    # è­˜åˆ¥é€£çºŒè¶¨å‹¢æœŸé–“
    current_trend = None
    trend_start = None
    
    for i, trend in enumerate(trends):
        if abs(trend['trend_strength']) > threshold and trend['p_value'] < 0.05:
            trend_direction = "ä¸Šå‡" if trend['slope'] > 0 else "ä¸‹é™"
            
            if current_trend == trend_direction:
                continue  # å»¶çºŒç•¶å‰è¶¨å‹¢
            else:
                # çµæŸå‰ä¸€å€‹è¶¨å‹¢æœŸé–“
                if current_trend is not None and trend_start is not None:
                    continuous_periods.append({
                        'start_index': trend_start,
                        'end_index': i - 1,
                        'start_date': dates[trend_start + window],
                        'end_date': dates[i - 1 + window],
                        'direction': current_trend,
                        'duration': i - trend_start,
                        'avg_slope': np.mean([t['slope'] for t in trends[trend_start:i]])
                    })
                
                # é–‹å§‹æ–°çš„è¶¨å‹¢æœŸé–“
                current_trend = trend_direction
                trend_start = i
        else:
            # çµæŸç•¶å‰è¶¨å‹¢æœŸé–“
            if current_trend is not None and trend_start is not None:
                continuous_periods.append({
                    'start_index': trend_start,
                    'end_index': i - 1,
                    'start_date': dates[trend_start + window],
                    'end_date': dates[i - 1 + window],
                    'direction': current_trend,
                    'duration': i - trend_start,
                    'avg_slope': np.mean([t['slope'] for t in trends[trend_start:i]])
                })
            current_trend = None
            trend_start = None
    
    return {
        'trends': trends,
        'continuous_periods': continuous_periods,
        'window': window
    }

def calculate_trend_acceleration(values: np.ndarray, window: int) -> Dict:
    """è¨ˆç®—è¶‹åŠ¿åŠ é€Ÿåº¦"""
    accelerations = []
    velocities = []
    
    # è¨ˆç®—ä¸€éšå·®åˆ† (é€Ÿåº¦)
    for i in range(window, len(values) - 1):
        velocity = values[i] - values[i-1]
        velocities.append(velocity)
    
    # è¨ˆç®—äºŒéšå·®åˆ† (åŠ é€Ÿåº¦)
    for i in range(1, len(velocities)):
        acceleration = velocities[i] - velocities[i-1]
        accelerations.append(acceleration)
    
    return {
        'velocities': np.array(velocities),
        'accelerations': np.array(accelerations),
        'start_index': window + 1
    }

def evaluate_trend_strength(values: np.ndarray, short_window: int, long_window: int) -> Dict:
    """è©•ä¼°è¶¨å‹¢å¼·åº¦"""
    strengths = []
    consistencies = []
    
    for i in range(long_window, len(values)):
        # çŸ­æœŸè¶¨å‹¢å¼·åº¦
        short_data = values[i-short_window:i]
        short_x = np.arange(len(short_data))
        short_slope, _, short_r, short_p, _ = stats.linregress(short_x, short_data)
        short_strength = abs(short_slope) * abs(short_r) if short_p < 0.05 else 0
        
        # é•·æœŸè¶¨å‹¢å¼·åº¦
        long_data = values[i-long_window:i]
        long_x = np.arange(len(long_data))
        long_slope, _, long_r, long_p, _ = stats.linregress(long_x, long_data)
        long_strength = abs(long_slope) * abs(long_r) if long_p < 0.05 else 0
        
        # è¶¨å‹¢ä¸€è‡´æ€§
        consistency = 1.0 if (short_slope * long_slope) > 0 else 0.0
        
        strengths.append({
            'short_strength': short_strength,
            'long_strength': long_strength,
            'combined_strength': (short_strength + long_strength) / 2
        })
        consistencies.append(consistency)
    
    return {
        'strengths': strengths,
        'consistencies': np.array(consistencies),
        'start_index': long_window
    }

def display_level_shift_results(results: Dict, kpi_data: pd.DataFrame, 
                              kpi_name: str, fab_name: str):
    """é¡¯ç¤º Level Shift æª¢æ¸¬çµæœ"""
    shifts = results['shifts']
    explanations = results['explanations']
    values = results['values']
    dates = results['dates']
    
    # çµ±è¨ˆæ‘˜è¦
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("æª¢æ¸¬åˆ° Level Shift", len(shifts))
    
    with col2:
        if shifts:
            avg_magnitude = np.mean([s['change_pct'] for s in shifts])
            st.metric("å¹³å‡è®ŠåŒ–å¹…åº¦", f"{avg_magnitude:.2f}%")
        else:
            st.metric("å¹³å‡è®ŠåŒ–å¹…åº¦", "N/A")
    
    with col3:
        if shifts:
            up_shifts = sum(1 for s in shifts if s['change_direction'] == 'ä¸Šå‡')
            st.metric("ä¸Šå‡ Level Shift", up_shifts)
        else:
            st.metric("ä¸Šå‡ Level Shift", 0)
    
    with col4:
        if shifts:
            down_shifts = sum(1 for s in shifts if s['change_direction'] == 'ä¸‹é™')
            st.metric("ä¸‹é™ Level Shift", down_shifts)
        else:
            st.metric("ä¸‹é™ Level Shift", 0)
    
    # è¦–è¦ºåŒ–
    fig = go.Figure()
    
    # åŸå§‹æ•¸æ“š
    fig.add_trace(go.Scatter(
        x=dates,
        y=values,
        mode='lines+markers',
        name='åŸå§‹æ•¸æ“š',
        line=dict(color='blue', width=2),
        marker=dict(size=4)
    ))
    
    # æ¨™è¨˜ Level Shift é»
    if shifts:
        shift_dates = [s['date'] for s in shifts]
        shift_values = [values[s['index']] for s in shifts]
        shift_colors = ['red' if s['change_direction'] == 'ä¸‹é™' else 'green' for s in shifts]
        
        fig.add_trace(go.Scatter(
            x=shift_dates,
            y=shift_values,
            mode='markers',
            name='Level Shift',
            marker=dict(
                color=shift_colors,
                size=12,
                symbol='star',
                line=dict(color='black', width=1)
            )
        ))
        
        # æ·»åŠ æ¨™è¨»
        for i, shift in enumerate(shifts):
            fig.add_annotation(
                x=shift['date'],
                y=values[shift['index']],
                text=f"{shift['change_direction']}<br>{shift['change_pct']:.1f}%",
                showarrow=True,
                arrowhead=2,
                arrowcolor=shift_colors[i],
                bgcolor=shift_colors[i],
                bordercolor="white",
                font=dict(color="white", size=10)
            )
    
    fig.update_layout(
        title=f"{fab_name} - {kpi_name} Level Shift æª¢æ¸¬çµæœ",
        xaxis_title="æ™‚é–“",
        yaxis_title="æ•¸å€¼",
        height=500,
        hovermode='x unified'
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # è©³ç´°çµæœè¡¨æ ¼
    if shifts:
        st.subheader("ğŸ“‹ Level Shift è©³ç´°ä¿¡æ¯")
        
        shift_details = []
        for i, (shift, explanation) in enumerate(zip(shifts, explanations)):
            shift_details.append({
                'æ™‚é–“': shift['date'].strftime('%Y-%m-%d'),
                'è®ŠåŒ–æ–¹å‘': shift['change_direction'],
                'è®ŠåŒ–å¹…åº¦': f"{shift['change_pct']:.2f}%",
                'è®ŠåŒ–å‰å‡å€¼': f"{shift['before_mean']:.2f}",
                'è®ŠåŒ–å¾Œå‡å€¼': f"{shift['after_mean']:.2f}",
                'På€¼': f"{shift['p_value']:.4f}",
                'è§£é‡‹èªªæ˜': explanation
            })
        
        df = pd.DataFrame(shift_details)
        st.dataframe(df, use_container_width=True)

def display_momentum_results(results: Dict, kpi_data: pd.DataFrame, 
                           kpi_name: str, fab_name: str):
    """é¡¯ç¤ºè¶¨å‹¢å‹•é‡åˆ†æçµæœ"""
    values = results['values']
    dates = results['dates']
    
    # å‰µå»ºå­åœ–
    n_plots = len([k for k in results.keys() if k not in ['values', 'dates', 'short_window', 'long_window']])
    fig = make_subplots(
        rows=n_plots + 1, cols=1,
        subplot_titles=['åŸå§‹æ™‚åºæ•¸æ“š'] + [k.replace('_', ' ').title() for k in results.keys() 
                                      if k not in ['values', 'dates', 'short_window', 'long_window']],
        vertical_spacing=0.08,
        shared_xaxes=True
    )
    
    # åŸå§‹æ•¸æ“š
    fig.add_trace(
        go.Scatter(x=dates, y=values, mode='lines+markers', name='åŸå§‹æ•¸æ“š'),
        row=1, col=1
    )
    
    current_row = 2
    
    # è¶¨å‹¢å‹•é‡åˆ†æ
    if 'momentum' in results:
        momentum = results['momentum']
        start_idx = momentum['start_index']
        
        fig.add_trace(
            go.Scatter(x=dates[start_idx:], y=momentum['short_trends'], 
                      name=f'çŸ­æœŸè¶¨å‹¢ ({results["short_window"]}å¤©)', line=dict(color='blue')),
            row=current_row, col=1
        )
        fig.add_trace(
            go.Scatter(x=dates[start_idx:], y=momentum['long_trends'], 
                      name=f'é•·æœŸè¶¨å‹¢ ({results["long_window"]}å¤©)', line=dict(color='red')),
            row=current_row, col=1
        )
        fig.add_trace(
            go.Scatter(x=dates[start_idx:], y=momentum['momentum_signals'], 
                      name='å‹•é‡ä¿¡è™Ÿ', line=dict(color='green')),
            row=current_row, col=1
        )
        current_row += 1
    
    # é€£çºŒè¶¨å‹¢æª¢æ¸¬
    if 'continuous_trends' in results:
        continuous = results['continuous_trends']
        trends = [t['trend_strength'] for t in continuous['trends']]
        trend_dates = dates[continuous['window']:]
        
        fig.add_trace(
            go.Scatter(x=trend_dates, y=trends, mode='lines', name='è¶¨å‹¢å¼·åº¦'),
            row=current_row, col=1
        )
        
        # æ¨™è¨˜é€£çºŒè¶¨å‹¢æœŸé–“
        for period in continuous['continuous_periods']:
            fig.add_vrect(
                x0=period['start_date'], x1=period['end_date'],
                fillcolor="red" if period['direction'] == "ä¸‹é™" else "green",
                opacity=0.2, line_width=0,
                row=current_row, col=1
            )
        
        current_row += 1
    
    # åŠ é€Ÿåº¦åˆ†æ
    if 'acceleration' in results:
        accel = results['acceleration']
        start_idx = accel['start_index']
        
        fig.add_trace(
            go.Scatter(x=dates[start_idx:start_idx+len(accel['accelerations'])], 
                      y=accel['accelerations'], mode='lines', name='è¶¨å‹¢åŠ é€Ÿåº¦'),
            row=current_row, col=1
        )
        current_row += 1
    
    # è¶¨å‹¢å¼·åº¦è©•ä¼°
    if 'strength' in results:
        strength = results['strength']
        start_idx = strength['start_index']
        combined_strengths = [s['combined_strength'] for s in strength['strengths']]
        
        fig.add_trace(
            go.Scatter(x=dates[start_idx:], y=combined_strengths, 
                      mode='lines', name='ç¶œåˆè¶¨å‹¢å¼·åº¦'),
            row=current_row, col=1
        )
        fig.add_trace(
            go.Scatter(x=dates[start_idx:], y=strength['consistencies'], 
                      mode='lines', name='è¶¨å‹¢ä¸€è‡´æ€§'),
            row=current_row, col=1
        )
        current_row += 1
    
    fig.update_layout(
        height=200 * (n_plots + 1),
        title_text=f"{fab_name} - {kpi_name} è¶¨å‹¢å‹•é‡åˆ†æ",
        showlegend=True
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # åˆ†ææ‘˜è¦
    display_momentum_summary(results, kpi_name)

def display_momentum_summary(results: Dict, kpi_name: str):
    """é¡¯ç¤ºå‹•é‡åˆ†ææ‘˜è¦"""
    st.subheader("ğŸ“Š åˆ†ææ‘˜è¦")
    
    # é€£çºŒè¶¨å‹¢çµ±è¨ˆ
    if 'continuous_trends' in results:
        continuous = results['continuous_trends']
        periods = continuous['continuous_periods']
        
        if periods:
            st.write("**é€£çºŒè¶¨å‹¢æœŸé–“:**")
            for i, period in enumerate(periods):
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric(f"æœŸé–“ {i+1}", period['direction'])
                with col2:
                    st.metric("æŒçºŒå¤©æ•¸", f"{period['duration']}å¤©")
                with col3:
                    st.metric("å¹³å‡æ–œç‡", f"{period['avg_slope']:.4f}")
                with col4:
                    start_str = period['start_date'].strftime('%m-%d')
                    end_str = period['end_date'].strftime('%m-%d')
                    st.metric("æ™‚é–“ç¯„åœ", f"{start_str}~{end_str}")
                
                # ç”Ÿæˆè§£é‡‹
                explanation = generate_trend_explanation(period, kpi_name)
                st.info(f"ğŸ’¡ **è§£é‡‹**: {explanation}")
                st.divider()

def generate_level_shift_explanation(before_mean: float, after_mean: float, 
                                   change_pct: float, direction: str, 
                                   p_value: float, window: int) -> str:
    """ç”Ÿæˆ Level Shift è§£é‡‹"""
    magnitude_desc = "é¡¯è‘—" if change_pct > 15 else "ä¸­ç­‰" if change_pct > 8 else "è¼•å¾®"
    confidence = "é«˜åº¦" if p_value < 0.01 else "ä¸­ç­‰"
    
    explanation = f"åœ¨ {window} å¤©çš„æ¯”è¼ƒçª—å£ä¸­ï¼ŒKPI å‡ºç¾äº† {magnitude_desc} çš„ {direction} Level Shiftã€‚"
    explanation += f"è®ŠåŒ–å‰å¾Œçš„å¹³å‡å€¼å¾ {before_mean:.2f} è®Šç‚º {after_mean:.2f}ï¼Œ"
    explanation += f"è®ŠåŒ–å¹…åº¦é” {change_pct:.2f}%ï¼Œçµ±è¨ˆé¡¯è‘—æ€§ç‚º {confidence} ä¿¡å¿ƒæ°´æº– (p={p_value:.4f})ã€‚"
    
    if change_pct > 20:
        explanation += " é€™æ˜¯ä¸€å€‹éå¸¸é¡¯è‘—çš„æ°´æº–è®ŠåŒ–ï¼Œå»ºè­°æ·±å…¥èª¿æŸ¥å¯èƒ½çš„æ ¹æœ¬åŸå› ã€‚"
    elif change_pct > 10:
        explanation += " é€™å€‹è®ŠåŒ–å€¼å¾—é—œæ³¨ï¼Œå¯èƒ½åæ˜ äº†è£½ç¨‹æˆ–è¨­å‚™çš„è®ŠåŒ–ã€‚"
    else:
        explanation += " é€™æ˜¯ä¸€å€‹ç›¸å°è¼ƒå°ä½†çµ±è¨ˆé¡¯è‘—çš„è®ŠåŒ–ã€‚"
    
    return explanation

def generate_trend_explanation(period: Dict, kpi_name: str) -> str:
    """ç”Ÿæˆè¶¨å‹¢è§£é‡‹"""
    direction = period['direction']
    duration = period['duration']
    avg_slope = period['avg_slope']
    
    if duration >= 14:
        duration_desc = "é•·æœŸ"
    elif duration >= 7:
        duration_desc = "ä¸­æœŸ"
    else:
        duration_desc = "çŸ­æœŸ"
    
    slope_magnitude = abs(avg_slope)
    if slope_magnitude > 1.0:
        intensity = "å¼·çƒˆ"
    elif slope_magnitude > 0.1:
        intensity = "æ˜é¡¯"
    else:
        intensity = "æº«å’Œ"
    
    explanation = f"æª¢æ¸¬åˆ° {duration_desc} çš„ {intensity} {direction} è¶¨å‹¢ï¼Œ"
    explanation += f"æŒçºŒäº† {duration} å¤©ï¼Œå¹³å‡è®ŠåŒ–ç‡ç‚º {avg_slope:.4f}/å¤©ã€‚"
    
    if direction == "ä¸Šå‡":
        if kpi_name in ["Yield", "Equipment_Utilization", "Quality_Score"]:
            explanation += " é€™æ˜¯ä¸€å€‹ç©æ¥µçš„è¶¨å‹¢ï¼Œè¡¨æ˜ç¸¾æ•ˆæ­£åœ¨æ”¹å–„ã€‚"
        elif kpi_name in ["Defect_Rate", "Cycle_Time", "Cost_Per_Unit"]:
            explanation += " é€™å€‹ä¸Šå‡è¶¨å‹¢éœ€è¦é—œæ³¨ï¼Œå¯èƒ½è¡¨æ˜å­˜åœ¨å•é¡Œã€‚"
    else:  # ä¸‹é™
        if kpi_name in ["Yield", "Equipment_Utilization", "Quality_Score"]:
            explanation += " é€™æ˜¯ä¸€å€‹éœ€è¦é—œæ³¨çš„è² é¢è¶¨å‹¢ï¼Œå»ºè­°èª¿æŸ¥åŸå› ã€‚"
        elif kpi_name in ["Defect_Rate", "Cycle_Time", "Cost_Per_Unit"]:
            explanation += " é€™æ˜¯ä¸€å€‹ç©æ¥µçš„ä¸‹é™è¶¨å‹¢ï¼Œè¡¨æ˜æƒ…æ³åœ¨æ”¹å–„ã€‚"
    
    if duration >= 21:
        explanation += " é•·æœŸè¶¨å‹¢çš„æŒçºŒæ€§è¡¨æ˜é€™å¯èƒ½æ˜¯ç³»çµ±æ€§è®ŠåŒ–ï¼Œè€Œééš¨æ©Ÿæ³¢å‹•ã€‚"
    
    return explanation