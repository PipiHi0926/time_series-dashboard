import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from matplotlib.patches import Rectangle
from datetime import datetime, timedelta
from typing import Optional, List, Dict
import warnings
warnings.filterwarnings('ignore')
from matplotlib_utils import render_matplotlib_figure, create_zscore_analysis_plot, create_iqr_analysis_plot, create_anomaly_plot

plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

st.set_page_config(
    page_title="FAB KPI OOB ç›£æ§ Dashboard",
    page_icon="ğŸ­",
    layout="wide",
    initial_sidebar_state="expanded"
)

def apply_basic_css():
    """æ‡‰ç”¨åŸºæœ¬CSSæ¨£å¼"""
    basic_css = """
    <style>
    .metric-container {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
        border: 1px solid #e9ecef;
    }
    .js-plotly-plot {
        background-color: #ffffff !important;
    }
    </style>
    """
    st.markdown(basic_css, unsafe_allow_html=True)


def prepare_plotly_data(x_data, y_data):
    """æº–å‚™ Plotly åœ–è¡¨æ•¸æ“šï¼Œç¢ºä¿æ ¼å¼æ­£ç¢º - è½‰æ›ç‚º Python list"""
    x_clean = to_plotly_list(x_data)
    y_clean = to_plotly_list(y_data)
    
    # ç¢ºä¿æ•¸æ“šé•·åº¦ä¸€è‡´
    min_len = min(len(x_clean), len(y_clean))
    x_clean = x_clean[:min_len]
    y_clean = y_clean[:min_len]
    
    return x_clean, y_clean

def ensure_data_format(df):
    """ç¢ºä¿æ•¸æ“šæ ¼å¼æ­£ç¢º"""
    if df is None:
        return None
    
    # ç¢ºä¿å¿…è¦æ¬„ä½å­˜åœ¨
    required_columns = ['FAB', 'VALUE', 'KPI', 'REPORT_TIME']
    if not all(col in df.columns for col in required_columns):
        raise ValueError(f"ç¼ºå°‘å¿…è¦æ¬„ä½: {required_columns}")
    
    # è¤‡è£½æ•¸æ“šé¿å…ä¿®æ”¹åŸå§‹æ•¸æ“š
    df = df.copy()
    
    # ç¢ºä¿æ•¸æ“šé¡å‹æ­£ç¢º
    df['REPORT_TIME'] = pd.to_datetime(df['REPORT_TIME'], errors='coerce')
    df['VALUE'] = pd.to_numeric(df['VALUE'], errors='coerce')
    df['FAB'] = df['FAB'].astype(str)
    df['KPI'] = df['KPI'].astype(str)
    
    # ç§»é™¤ç„¡æ•ˆæ•¸å€¼
    df = df.dropna(subset=['VALUE', 'REPORT_TIME'])
    
    # ç¢ºä¿ç´¢å¼•æ˜¯é€£çºŒçš„
    df = df.sort_values(['FAB', 'KPI', 'REPORT_TIME']).reset_index(drop=True)
    
    return df

def main():
    # æ‡‰ç”¨åŸºæœ¬CSS
    apply_basic_css()
    
    st.title("ğŸ­ FAB KPI æ™‚åºè³‡æ–™ç•°å¸¸ç›£æ§ Dashboard")
    
    # Initialize session state for data
    if 'raw_data' not in st.session_state:
        st.session_state.raw_data = None
    if 'selected_fab' not in st.session_state:
        st.session_state.selected_fab = None
    if 'fab_data' not in st.session_state:
        st.session_state.fab_data = None
    if 'available_kpis' not in st.session_state:
        st.session_state.available_kpis = []
    if 'selected_kpi' not in st.session_state:
        st.session_state.selected_kpi = None
    
    # Sidebar navigation
    st.sidebar.title("ğŸ” åˆ†ææ–¹æ³•")
    analysis_method = st.sidebar.radio(
        "é¸æ“‡åˆ†ææ–¹æ³•:",
        ["KPI å¿«é€Ÿåˆ†æ", "æ•¸æ“šä¸Šå‚³èˆ‡FABé¸æ“‡", "æ•˜è¿°çµ±è¨ˆåˆ†æ", "çµ±è¨ˆæ–¹æ³•åµæ¸¬", "ç§»å‹•å¹³å‡åµæ¸¬", "å­£ç¯€æ€§åˆ†è§£åµæ¸¬", "æ™‚åºåˆ†æ", "KPIæ‰¹é‡ç›£æ§", "Level Shift æª¢æ¸¬", "è¶¨å‹¢å‹•é‡åˆ†æ", "ç•°å¸¸è¶¨å‹¢åˆ†æ"]
    )
    
    # åœ¨å´é‚Šæ¬„é¡¯ç¤ºç•¶å‰é¸æ“‡çš„è³‡æ–™ç‹€æ…‹
    show_sidebar_data_status()
    
    # Route to different pages based on selection
    if analysis_method == "KPI å¿«é€Ÿåˆ†æ":
        kpi_quick_analysis_page()
    elif analysis_method == "æ•¸æ“šä¸Šå‚³èˆ‡FABé¸æ“‡":
        data_upload_fab_selection_page()
    elif analysis_method == "æ•˜è¿°çµ±è¨ˆåˆ†æ":
        from descriptive_stats import descriptive_statistics_page
        descriptive_statistics_page()
    elif analysis_method == "çµ±è¨ˆæ–¹æ³•åµæ¸¬":
        statistical_detection_page()
    elif analysis_method == "ç§»å‹•å¹³å‡åµæ¸¬":
        moving_average_detection_page()
    elif analysis_method == "å­£ç¯€æ€§åˆ†è§£åµæ¸¬":
        seasonal_decomposition_page()
    elif analysis_method == "æ™‚åºåˆ†æ":
        from time_series_analysis import time_series_analysis_page
        time_series_analysis_page()
    elif analysis_method == "KPIæ‰¹é‡ç›£æ§":
        from batch_monitoring import batch_kpi_monitoring_page
        batch_kpi_monitoring_page()
    elif analysis_method == "Level Shift æª¢æ¸¬":
        from advanced_analysis import level_shift_detection_page
        level_shift_detection_page()
    elif analysis_method == "è¶¨å‹¢å‹•é‡åˆ†æ":
        from advanced_analysis import trend_momentum_analysis_page
        trend_momentum_analysis_page()
    elif analysis_method == "ç•°å¸¸è¶¨å‹¢åˆ†æ":
        from time_series_analysis import anomaly_trend_analysis_page
        anomaly_trend_analysis_page()

def show_sidebar_data_status():
    """åœ¨å´é‚Šæ¬„é¡¯ç¤ºç•¶å‰è³‡æ–™ç‹€æ…‹"""
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ“Š ç•¶å‰è³‡æ–™ç‹€æ…‹")
    
    if st.session_state.raw_data is not None:
        st.sidebar.success("âœ… è³‡æ–™å·²è¼‰å…¥")
        st.sidebar.write(f"ğŸ“ˆ ç¸½ç­†æ•¸: {len(st.session_state.raw_data):,}")
        st.sidebar.write(f"ğŸ­ FABæ•¸: {st.session_state.raw_data['FAB'].nunique()}")
        st.sidebar.write(f"ğŸ“Š KPIæ•¸: {st.session_state.raw_data['KPI'].nunique()}")
        
        if st.session_state.selected_fab:
            st.sidebar.info(f"ğŸ¯ å·²é¸FAB: {st.session_state.selected_fab}")
            if st.session_state.selected_kpi:
                st.sidebar.info(f"ğŸ“ˆ å·²é¸KPI: {st.session_state.selected_kpi}")
        
        # å¿«é€Ÿåˆ‡æ› FAB å’Œ KPI
        if st.session_state.raw_data is not None:
            available_fabs = sorted(st.session_state.raw_data['FAB'].unique())
            current_fab = st.sidebar.selectbox(
                "ğŸ­ å¿«é€Ÿåˆ‡æ› FAB:",
                options=available_fabs,
                index=to_plotly_list(available_fabs.index(st.session_state.selected_fab)) if st.session_state.selected_fab in available_fabs else 0,
                key=to_plotly_list("sidebar_fab_selector"
            ))
            
            if current_fab != st.session_state.selected_fab:
                st.session_state.selected_fab = current_fab
                fab_data = st.session_state.raw_data[st.session_state.raw_data['FAB'] == current_fab]
                st.session_state.fab_data = fab_data
                st.session_state.available_kpis = sorted(fab_data['KPI'].unique())
                st.session_state.selected_kpi = st.session_state.available_kpis[0] if st.session_state.available_kpis else None
                st.info("ğŸ”„ è«‹é‡æ–°æ•´ç†é é¢ä»¥æ›´æ–°é¸æ“‡")
            
            if st.session_state.available_kpis:
                current_kpi = st.sidebar.selectbox(
                    "ğŸ“ˆ å¿«é€Ÿåˆ‡æ› KPI:",
                    options=st.session_state.available_kpis,
                    index=to_plotly_list(st.session_state.available_kpis.index(st.session_state.selected_kpi)) if st.session_state.selected_kpi in st.session_state.available_kpis else 0,
                    key=to_plotly_list("sidebar_kpi_selector"
                ))
                
                if current_kpi != st.session_state.selected_kpi:
                    st.session_state.selected_kpi = current_kpi
    else:
        st.sidebar.warning("âš ï¸ å°šæœªè¼‰å…¥è³‡æ–™")
        if st.sidebar.button("ğŸ¯ è¼‰å…¥ç¯„ä¾‹è³‡æ–™", key=to_plotly_list("sidebar_load_sample")):
            sample_data = generate_fab_sample_data()
            sample_data = ensure_data_format(sample_data)
            st.session_state.raw_data = sample_data
            # è‡ªå‹•é¸æ“‡ç¬¬ä¸€å€‹ FAB å’Œ KPI
            first_fab = sample_data['FAB'].iloc[0]
            st.session_state.selected_fab = first_fab
            fab_data = sample_data[sample_data['FAB'] == first_fab]
            st.session_state.fab_data = fab_data
            st.session_state.available_kpis = sorted(fab_data['KPI'].unique())
            st.session_state.selected_kpi = st.session_state.available_kpis[0] if st.session_state.available_kpis else None
            st.info("ğŸ”„ è«‹é‡æ–°æ•´ç†é é¢ä»¥æ›´æ–°é¸æ“‡")
    
    # ç§»é™¤ä¸»é¡Œåˆ‡æ›åŠŸèƒ½ä»¥ç›¸å®¹ Streamlit 1.12.0

def kpi_quick_analysis_page():
    """KPI å¿«é€Ÿåˆ†æé é¢ - é è¨­é¦–é """
    st.header("ğŸ¯ KPI å¿«é€Ÿåˆ†æ")
    
    # æª¢æŸ¥æ˜¯å¦æœ‰è³‡æ–™
    if st.session_state.raw_data is None:
        st.info("ğŸ“ é–‹å§‹åˆ†æå‰ï¼Œè«‹è¼‰å…¥è³‡æ–™")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ¯ ä½¿ç”¨ç¯„ä¾‹è³‡æ–™")
            st.write("è¼‰å…¥åŒ…å« 4 å€‹ FABã€12 ç¨® KPI çš„ç¯„ä¾‹è³‡æ–™ï¼ŒåŒ…å«çœŸå¯¦çš„ç•°å¸¸æ¨¡å¼å’Œç‰¹æ®Šäº‹ä»¶ã€‚")
            
            if st.button("ğŸš€ è¼‰å…¥ç¯„ä¾‹è³‡æ–™é–‹å§‹åˆ†æ", key=to_plotly_list("quick_load_sample")):
                with st.spinner("æ­£åœ¨è¼‰å…¥ç¯„ä¾‹è³‡æ–™..."):
                    sample_data = generate_fab_sample_data()
                    sample_data = ensure_data_format(sample_data)
                    st.session_state.raw_data = sample_data
                    # è‡ªå‹•é¸æ“‡ç¬¬ä¸€å€‹ FAB å’Œ KPI
                    first_fab = sample_data['FAB'].iloc[0]
                    st.session_state.selected_fab = first_fab
                    fab_data = sample_data[sample_data['FAB'] == first_fab]
                    st.session_state.fab_data = fab_data
                    st.session_state.available_kpis = sorted(fab_data['KPI'].unique())
                    st.session_state.selected_kpi = st.session_state.available_kpis[0] if st.session_state.available_kpis else None
                
                st.success("âœ… ç¯„ä¾‹è³‡æ–™è¼‰å…¥å®Œæˆï¼ğŸ”„ è«‹é‡æ–°æ•´ç†é é¢")
        
        with col2:
            st.subheader("ğŸ“ ä¸Šå‚³è‡ªå·±çš„è³‡æ–™")
            st.write("ä¸Šå‚³ç¬¦åˆ FAB KPI æ ¼å¼çš„ CSV æˆ– Excel æª”æ¡ˆã€‚")
            
            uploaded_file = st.file_uploader(
                "é¸æ“‡æª”æ¡ˆ",
                type=['csv', 'xlsx', 'xls'],
                key=to_plotly_list("quick_upload"
            ))
            
            if uploaded_file is not None:
                try:
                    if uploaded_file.name.endswith('.csv'):
                        df = pd.read_csv(uploaded_file)
                    else:
                        df = pd.read_excel(uploaded_file)
                    
                    # ç¢ºä¿æ•¸æ“šæ ¼å¼æ­£ç¢º
                    try:
                        df = ensure_data_format(df)
                        st.session_state.raw_data = df
                        # è‡ªå‹•é¸æ“‡ç¬¬ä¸€å€‹ FAB å’Œ KPI
                        first_fab = df['FAB'].iloc[0]
                        st.session_state.selected_fab = first_fab
                        fab_data = df[df['FAB'] == first_fab]
                        st.session_state.fab_data = fab_data
                        st.session_state.available_kpis = sorted(fab_data['KPI'].unique())
                        st.session_state.selected_kpi = st.session_state.available_kpis[0] if st.session_state.available_kpis else None
                        
                        st.success("âœ… è³‡æ–™ä¸Šå‚³æˆåŠŸï¼ğŸ”„ è«‹é‡æ–°æ•´ç†é é¢")
                    except Exception as format_error:
                        st.error(f"âŒ æ•¸æ“šæ ¼å¼éŒ¯èª¤: {str(format_error)}")
                        st.info("ğŸ’¡ è«‹ç¢ºä¿: 1) åŒ…å« FAB, VALUE, KPI, REPORT_TIME æ¬„ä½ 2) VALUE ç‚ºæ•¸å€¼ 3) REPORT_TIME ç‚ºæœ‰æ•ˆæ—¥æœŸæ ¼å¼")
                except Exception as e:
                    st.error(f"âŒ è®€å–æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        
        return
    
    # æœ‰è³‡æ–™æ™‚çš„å¿«é€Ÿåˆ†æä»‹é¢
    st.subheader(f"ğŸ­ {st.session_state.selected_fab} - {st.session_state.selected_kpi} åˆ†æ")
    
    # ç²å–ç•¶å‰é¸æ“‡çš„ KPI è³‡æ–™
    if st.session_state.fab_data is not None and st.session_state.selected_kpi:
        kpi_data = st.session_state.fab_data[st.session_state.fab_data['KPI'] == st.session_state.selected_kpi].copy()
        kpi_data = kpi_data.sort_values('REPORT_TIME')
        
        if len(kpi_data) == 0:
            st.warning("âš ï¸ é¸æ“‡çš„ KPI ç„¡è³‡æ–™")
            return
        
        # å¿«é€Ÿçµ±è¨ˆ
        display_kpi_quick_stats(kpi_data, st.session_state.selected_kpi, st.session_state.selected_fab)
        
        # å¿«é€Ÿåˆ†æé¸é …
        st.subheader("ğŸ” å¿«é€Ÿç•°å¸¸åµæ¸¬")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸ“Š çµ±è¨ˆæ–¹æ³•åµæ¸¬", key=to_plotly_list("quick_statistical")):
                st.info("ğŸ’¡ è«‹å¾å·¦å´é¸å–®é¸æ“‡ã€Œçµ±è¨ˆæ–¹æ³•åµæ¸¬ã€é€²è¡Œåˆ†æ")
        
        with col2:
            if st.button("ğŸ“ˆ ç§»å‹•å¹³å‡åµæ¸¬", key=to_plotly_list("quick_ma")):
                st.info("ğŸ’¡ è«‹å¾å·¦å´é¸å–®é¸æ“‡ã€Œç§»å‹•å¹³å‡åµæ¸¬ã€é€²è¡Œåˆ†æ")
        
        with col3:
            if st.button("ğŸ”„ å­£ç¯€æ€§åˆ†è§£", key=to_plotly_list("quick_seasonal")):
                st.info("ğŸ’¡ è«‹å¾å·¦å´é¸å–®é¸æ“‡ã€Œå­£ç¯€æ€§åˆ†è§£åµæ¸¬ã€é€²è¡Œåˆ†æ")
        
        # åŸ·è¡ŒåŸºæœ¬çš„ç•°å¸¸åµæ¸¬é è¦½
        st.subheader("ğŸ“ˆ åŸºæœ¬è¶¨å‹¢èˆ‡ç•°å¸¸é è¦½")
        
        # ç°¡å–®çš„ Z-Score ç•°å¸¸åµæ¸¬
        values = kpi_data['VALUE'].values
        mean_val = np.mean(values)
        std_val = np.std(values)
        z_scores = np.abs((values - mean_val) / std_val)
        outliers = z_scores > 2.0
        
        # å‰µå»ºåœ–è¡¨
        fig = go.Figure()
        
        # æº–å‚™æ•¸æ“š
        x_data, y_data = prepare_plotly_data(kpi_data['REPORT_TIME'], kpi_data['VALUE'])
        
        # åŸå§‹æ•¸æ“š
        fig.add_trace(go.Scatter(
            x=to_plotly_list(x_data), y=to_plotly_list(y_data),
            mode='lines+markers',
            name='åŸå§‹æ•¸æ“š',
            line=dict(color='blue', width=2),
            marker=dict(size=4)
        ))
        
        # ç•°å¸¸é»
        if np.any(outliers):
            outlier_x, outlier_y = prepare_plotly_data(
                kpi_data[outliers]['REPORT_TIME'], 
                kpi_data[outliers]['VALUE']
            )
            
            fig.add_trace(go.Scatter(
                x=to_plotly_list(outlier_x), y=to_plotly_list(outlier_y),
                mode='markers',
                name='å¯èƒ½ç•°å¸¸é»',
                marker=dict(color='red', size=8, symbol='x')
            ))
        
        # æ·»åŠ å‡å€¼ç·š
        fig.add_hline(y=to_plotly_list(mean_val), line_dash="dash", line_color="green", 
                     annotation_text=f"å¹³å‡å€¼: {mean_val:.2f}")
        
        # æ·»åŠ  2Ïƒ é–¾å€¼ç·š
        fig.add_hline(y=to_plotly_list(mean_val + 2*std_val), line_dash="dash", line_color="orange", 
                     annotation_text="ä¸Šé–¾å€¼ (2Ïƒ)")
        fig.add_hline(y=to_plotly_list(mean_val - 2*std_val), line_dash="dash", line_color="orange", 
                     annotation_text="ä¸‹é–¾å€¼ (2Ïƒ)")
        
        fig.update_layout(
            title=f"{st.session_state.selected_fab} - {st.session_state.selected_kpi} è¶¨å‹¢åœ–",
            xaxis_title="æ™‚é–“",
            yaxis_title="æ•¸å€¼",
            hovermode='x unified',
            height=500
        )
        
        st.plotly_chart(fig)
        
        # é¡¯ç¤ºç•°å¸¸çµ±è¨ˆ
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("è³‡æ–™é»æ•¸", len(kpi_data))
        
        with col2:
            st.metric("å¯èƒ½ç•°å¸¸é»", np.sum(outliers))
        
        with col3:
            anomaly_rate = np.sum(outliers) / len(kpi_data) * 100
            st.metric("ç•°å¸¸ç‡", f"{anomaly_rate:.1f}%")
        
        with col4:
            trend_slope = np.polyfit(range(len(values)), values, 1)[0]
            trend_direction = "ä¸Šå‡" if trend_slope > 0 else "ä¸‹é™" if trend_slope < 0 else "å¹³ç©©"
            st.metric("è¶¨å‹¢", trend_direction)
        
        # æä¾›é€²éšåˆ†æå»ºè­°
        st.subheader("ğŸ’¡ åˆ†æå»ºè­°")
        
        suggestions = get_analysis_suggestions(kpi_data, st.session_state.selected_kpi, outliers)
        for suggestion in suggestions:
            st.info(suggestion)

def display_kpi_quick_stats(kpi_data: pd.DataFrame, kpi_name: str, fab_name: str):
    """é¡¯ç¤º KPI å¿«é€Ÿçµ±è¨ˆ"""
    values = kpi_data['VALUE'].values
    
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.metric("æœ€æ–°å€¼", f"{values[-1]:.2f}")
    
    with col2:
        st.metric("å¹³å‡å€¼", f"{np.mean(values):.2f}")
    
    with col3:
        st.metric("æœ€å¤§å€¼", f"{np.max(values):.2f}")
    
    with col4:
        st.metric("æœ€å°å€¼", f"{np.min(values):.2f}")
    
    with col5:
        st.metric("æ¨™æº–å·®", f"{np.std(values):.2f}")

def get_analysis_suggestions(kpi_data: pd.DataFrame, kpi_name: str, outliers: np.ndarray) -> list:
    """æ ¹æ“š KPI ç‰¹æ€§å’Œæ•¸æ“šæä¾›åˆ†æå»ºè­°"""
    suggestions = []
    
    values = kpi_data['VALUE'].values
    outlier_rate = np.sum(outliers) / len(outliers) * 100
    
    # åŸºæ–¼ç•°å¸¸ç‡çš„å»ºè­°
    if outlier_rate > 5:
        suggestions.append(f"ğŸ”´ ç•°å¸¸ç‡è¼ƒé«˜ ({outlier_rate:.1f}%)ï¼Œå»ºè­°ä½¿ç”¨çµ±è¨ˆæ–¹æ³•é€²è¡Œæ·±åº¦åˆ†æ")
    elif outlier_rate > 2:
        suggestions.append(f"ğŸŸ¡ ç•°å¸¸ç‡ä¸­ç­‰ ({outlier_rate:.1f}%)ï¼Œå¯è€ƒæ…®ç§»å‹•å¹³å‡æ–¹æ³•æ¸›å°‘é›œè¨Š")
    else:
        suggestions.append(f"ğŸŸ¢ ç•°å¸¸ç‡è¼ƒä½ ({outlier_rate:.1f}%)ï¼Œæ•¸æ“šå“è³ªè‰¯å¥½")
    
    # åŸºæ–¼ KPI é¡å‹çš„å»ºè­°
    if kpi_name in ['Yield', 'First_Pass_Yield', 'Quality_Score']:
        suggestions.append("ğŸ’¡ è‰¯ç‡é¡æŒ‡æ¨™å»ºè­°é—œæ³¨é€£çºŒä¸‹é™è¶¨å‹¢ï¼Œå¯ä½¿ç”¨ç§»å‹•å¹³å‡åµæ¸¬")
    elif kpi_name in ['Defect_Rate', 'Rework_Rate']:
        suggestions.append("ğŸ’¡ ç¼ºé™·é¡æŒ‡æ¨™å»ºè­°ç›£æ§çªå¢ç•°å¸¸ï¼Œçµ±è¨ˆæ–¹æ³•æ•ˆæœè¼ƒå¥½")
    elif kpi_name in ['Throughput', 'Equipment_Utilization', 'OEE']:
        suggestions.append("ğŸ’¡ æ•ˆç‡é¡æŒ‡æ¨™å»ºè­°åˆ†æé€±æœŸæ€§æ¨¡å¼ï¼Œå¯å˜—è©¦å­£ç¯€æ€§åˆ†è§£")
    elif kpi_name in ['Cycle_Time', 'WIP_Level']:
        suggestions.append("ğŸ’¡ æ™‚é–“/åº«å­˜é¡æŒ‡æ¨™å»ºè­°ç›£æ§è¶¨å‹¢è®ŠåŒ–ï¼Œç§»å‹•å¹³å‡æ–¹æ³•é©ç”¨")
    
    # åŸºæ–¼æ•¸æ“šç‰¹æ€§çš„å»ºè­°
    data_range = len(kpi_data)
    if data_range > 90:
        suggestions.append("ğŸ“ˆ æ•¸æ“šå……è¶³ï¼Œå»ºè­°å˜—è©¦å­£ç¯€æ€§åˆ†è§£åˆ†æé•·æœŸè¶¨å‹¢")
    elif data_range < 30:
        suggestions.append("ğŸ“Š æ•¸æ“šè¼ƒå°‘ï¼Œå»ºè­°ä½¿ç”¨çµ±è¨ˆæ–¹æ³•æˆ–ç§»å‹•å¹³å‡åˆ†æ")
    
    return suggestions

def data_upload_fab_selection_page():
    st.header("ğŸ­ æ•¸æ“šä¸Šå‚³èˆ‡ FAB é¸æ“‡")
    
    # File upload
    col1, col2 = st.columns([3, 1])
    
    with col1:
        uploaded_file = st.file_uploader(
            "ä¸Šå‚³ FAB KPI è³‡æ–™æ–‡ä»¶ (CSV, Excel)", 
            type=['csv', 'xlsx', 'xls'],
            help="æª”æ¡ˆæ‡‰åŒ…å« FAB, VALUE, KPI, REPORT_TIME æ¬„ä½"
        )
    
    with col2:
        st.write("**ğŸ“‹ è³‡æ–™æ ¼å¼ç¯„ä¾‹**")
        # ç”Ÿæˆç¯„ä¾‹CSVå…§å®¹
        sample_csv = """FAB,KPI,REPORT_TIME,VALUE
FAB12A,Yield,2024-01-01,92.5
FAB12A,Throughput,2024-01-01,850
FAB14B,Yield,2024-01-01,89.5"""
        
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰æ ¼å¼ç¯„ä¾‹",
            data=sample_csv,
            file_name="fab_kpi_format_sample.csv",
            mime="text/csv",
            help="ä¸‹è¼‰æ¨™æº–çš„ FAB KPI è³‡æ–™æ ¼å¼ç¯„ä¾‹"
        )
        
        if st.button("ğŸ“– æ ¼å¼èªªæ˜"):
            st.info("""
            **æ¨™æº–æ ¼å¼è¦æ±‚:**
            - **FAB**: å·¥å» ä»£ç¢¼ (å¦‚: FAB12A)
            - **KPI**: æŒ‡æ¨™åç¨± (å¦‚: Yield)  
            - **REPORT_TIME**: æ—¥æœŸ (YYYY-MM-DD)
            - **VALUE**: æ•¸å€¼
            
            **æ³¨æ„äº‹é …:**
            - æ¬„ä½åç¨±éœ€å®Œå…¨ä¸€è‡´
            - æ—¥æœŸæ ¼å¼å»ºè­° YYYY-MM-DD
            - æ•¸å€¼æ¬„ä½ä¸å¯åŒ…å«æ–‡å­—
            """)    
    
    if uploaded_file is not None:
        try:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            
            st.success(f"âœ… æˆåŠŸè¼‰å…¥æ•¸æ“š: {df.shape[0]} è¡Œ, {df.shape[1]} åˆ—")
            
            # Validate required columns
            required_columns = ['FAB', 'VALUE', 'KPI', 'REPORT_TIME']
            missing_columns = [col for col in required_columns if col not in df.columns]
            
            if missing_columns:
                st.error(f"âŒ ç¼ºå°‘å¿…è¦æ¬„ä½: {', '.join(missing_columns)}")
                st.info("ğŸ’¡ æª”æ¡ˆå¿…é ˆåŒ…å«ä»¥ä¸‹æ¬„ä½: FAB, VALUE, KPI, REPORT_TIME")
                return
            
            # Convert REPORT_TIME to datetime
            try:
                df['REPORT_TIME'] = pd.to_datetime(df['REPORT_TIME'])
                df = df.sort_values(['FAB', 'KPI', 'REPORT_TIME'])
                st.success("âœ… æ™‚é–“æ¬„ä½è½‰æ›å®Œæˆ")
            except Exception as e:
                st.error(f"âŒ æ™‚é–“æ¬„ä½è½‰æ›å¤±æ•—: {str(e)}")
                return
            
            # Store raw data
            st.session_state.raw_data = df
            
            # Display basic info
            col1, col2 = st.columns(2)
            with col1:
                st.subheader("ğŸ“Š æ•¸æ“šé è¦½")
                st.dataframe(df.head(10))
            
            with col2:
                st.subheader("ğŸ“ˆ æ•¸æ“šçµ±è¨ˆ")
                st.write(f"**ç¸½è³‡æ–™ç­†æ•¸:** {len(df):,}")
                st.write(f"**FAB æ•¸é‡:** {df['FAB'].nunique()}")
                st.write(f"**KPI ç¨®é¡:** {df['KPI'].nunique()}")
                st.write(f"**æ™‚é–“ç¯„åœ:** {df['REPORT_TIME'].min().strftime('%Y-%m-%d')} ~ {df['REPORT_TIME'].max().strftime('%Y-%m-%d')}")
                
                st.write("**FAB åˆ—è¡¨:**")
                for fab in sorted(df['FAB'].unique()):
                    kpi_count = df[df['FAB'] == fab]['KPI'].nunique()
                    data_points = len(df[df['FAB'] == fab])
                    st.write(f"- {fab} ({kpi_count} KPIs, {data_points:,} ç­†)")
            
            # FAB Selection
            st.subheader("ğŸ­ é¸æ“‡ FAB")
            available_fabs = sorted(df['FAB'].unique())
            selected_fab = st.selectbox(
                "é¸æ“‡è¦åˆ†æçš„ FAB:",
                options=available_fabs,
                help="é¸æ“‡ç‰¹å®š FAB é€²è¡Œ KPI ç›£æ§åˆ†æ"
            )
            
            if selected_fab:
                fab_data = df[df['FAB'] == selected_fab].copy()
                available_kpis = sorted(fab_data['KPI'].unique())
                
                st.session_state.selected_fab = selected_fab
                st.session_state.fab_data = fab_data
                st.session_state.available_kpis = available_kpis
                
                st.success(f"âœ… å·²é¸æ“‡ FAB: {selected_fab}")
                
                # Show FAB characteristics if it's sample data
                if 'FAB12A' in available_fabs:  # æª¢æŸ¥æ˜¯å¦ç‚ºç¯„ä¾‹æ•¸æ“š
                    show_fab_characteristics(selected_fab)
                
                # Show FAB KPI overview
                st.subheader(f"ğŸ“ˆ {selected_fab} KPI æ¦‚è¦½")
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("KPI æ•¸é‡", len(available_kpis))
                with col2:
                    st.metric("è³‡æ–™é»æ•¸", len(fab_data))
                with col3:
                    latest_date = fab_data['REPORT_TIME'].max()
                    st.metric("æœ€æ–°æ•¸æ“š", latest_date.strftime('%Y-%m-%d'))
                with col4:
                    # è¨ˆç®—æ•´é«”è³‡æ–™å“è³ªè©•åˆ†
                    data_quality_score = calculate_data_quality_score(fab_data)
                    st.metric("è³‡æ–™å“è³ª", f"{data_quality_score:.1f}/10")
                
                # KPI selection for preview
                st.subheader("ğŸ” KPI é è¦½")
                preview_kpis = st.multiselect(
                    "é¸æ“‡è¦é è¦½çš„ KPI (æœ€å¤š5å€‹):",
                    options=available_kpis,
                    default=available_kpis[:min(5, len(available_kpis))],
                                    )
                
                if preview_kpis:
                    # Create pivot table for visualization
                    pivot_data = fab_data[fab_data['KPI'].isin(preview_kpis)].pivot_table(
                        index=to_plotly_list('REPORT_TIME'), 
                        columns='KPI', 
                        values=to_plotly_list('VALUE'), 
                        aggfunc='mean'
                    ).reset_index()
                    
                    # Create time series plot
                    fig = go.Figure()
                    for kpi in preview_kpis:
                        if kpi in pivot_data.columns:
                            fig.add_trace(go.Scatter(
                                x=to_plotly_list(pivot_data['REPORT_TIME']), y=to_plotly_list(pivot_data[kpi]),
                                mode='lines+markers',
                                name=kpi,
                                line=dict(width=2),
                                marker=dict(size=4)
                            ))
                    
                    fig.update_layout(
                        title=f"{selected_fab} - KPI æ™‚åºè³‡æ–™è¶¨å‹¢",
                        xaxis_title="å ±å‘Šæ™‚é–“",
                        yaxis_title="æ•¸å€¼",
                        hovermode='x unified',
                        height=500,
                        legend=dict(
                            orientation="h",
                            yanchor="bottom",
                            y=to_plotly_list(1.02),
                            xanchor="right",
                            x=to_plotly_list(1
                        ))
                    )
                    
                    st.plotly_chart(fig)
                
                st.info("ğŸ’¡ FAB æ•¸æ“šå·²æº–å‚™å®Œæˆï¼è«‹å¾å·¦å´é¸å–®é¸æ“‡åˆ†ææ–¹æ³•é€²è¡Œç›£æ§ã€‚")
                
        except Exception as e:
            st.error(f"âŒ è®€å–æ–‡ä»¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            st.info("ğŸ’¡ è«‹ç¢ºä¿æª”æ¡ˆæ ¼å¼æ­£ç¢ºï¼Œä¸”åŒ…å«å¿…è¦çš„æ¬„ä½ï¼šFAB, VALUE, KPI, REPORT_TIME")
    else:
        st.info("ğŸ“ è«‹ä¸Šå‚³åŒ…å« FAB KPI è³‡æ–™çš„æ–‡ä»¶é–‹å§‹åˆ†æ")
        
        # Sample data option
        st.subheader("ğŸ¯ ç¯„ä¾‹æ•¸æ“š")
        
        with st.expander("æŸ¥çœ‹ç¯„ä¾‹æ•¸æ“šèªªæ˜", expanded=False):
            st.markdown("""
            ### ğŸ“‹ ç¯„ä¾‹æ•¸æ“šç‰¹è‰²
            
            **ğŸ­ 4 å€‹ä¸åŒç‰¹æ€§çš„ FAB:**
            - **FAB12A** (28nm): æˆç†Ÿè£½ç¨‹ï¼Œé«˜ç©©å®šæ€§
            - **FAB14B** (14nm): é‡ç”¢çˆ¬å¡ä¸­ï¼Œä¸­ç­‰ç©©å®šæ€§  
            - **FAB16** (16nm): æˆç†Ÿè£½ç¨‹ï¼Œé«˜ç©©å®šæ€§
            - **FAB18** (7nm): æ–°è£½ç¨‹ï¼Œè¼ƒä½ç©©å®šæ€§
            
            **ğŸ“Š 12 ç¨® FAB KPI æŒ‡æ¨™:**
            - Yield (è‰¯ç‡), Throughput (ç”¢èƒ½), Defect_Rate (ç¼ºé™·ç‡)
            - Equipment_Utilization (è¨­å‚™åˆ©ç”¨ç‡), Cycle_Time (é€±æœŸæ™‚é–“)
            - WIP_Level (åœ¨è£½å“æ°´æº–), Cost_Per_Unit (å–®ä½æˆæœ¬)
            - Quality_Score (å“è³ªåˆ†æ•¸), OEE (æ•´é«”è¨­å‚™æ•ˆç‡)
            - First_Pass_Yield (é¦–æ¬¡é€šéè‰¯ç‡), Rework_Rate (é‡å·¥ç‡)
            - Critical_Dimension (é—œéµå°ºå¯¸å‡å‹»æ€§)
            
            **âš¡ ç‰¹æ®Šäº‹ä»¶æ¨¡æ“¬:**
            - è¨­å‚™æ•…éšœã€è£½ç¨‹æ”¹å–„ã€åŸæ–™çŸ­ç¼º
            - æ–°é…æ–¹å°å…¥ã€è¨­å‚™ç¶­è­·ã€ç”¢èƒ½æ“´å……
            
            **ğŸ“ˆ è³‡æ–™ç‰¹æ€§:**
            - 2å¹´æ¯æ—¥è³‡æ–™ (2023-2024)
            - åŒ…å«è¶¨å‹¢ã€å­£ç¯€æ€§ã€é€±æœŸæ€§
            - çœŸå¯¦çš„ç•°å¸¸æ¨¡å¼å’Œäº‹ä»¶å½±éŸ¿
            """)
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ¯ è¼‰å…¥ç¯„ä¾‹æ•¸æ“š"):
                with st.spinner("æ­£åœ¨ç”Ÿæˆç¯„ä¾‹æ•¸æ“š..."):
                    sample_data = generate_fab_sample_data()
                    sample_data = ensure_data_format(sample_data)
                    st.session_state.raw_data = sample_data
                st.success("âœ… ç¯„ä¾‹æ•¸æ“šå·²è¼‰å…¥ï¼è«‹é¸æ“‡ FAB é€²è¡Œåˆ†æã€‚ğŸ”„ è«‹é‡æ–°æ•´ç†é é¢")
        
        with col2:
            if st.button("ğŸ“Š é è¦½ç¯„ä¾‹çµ±è¨ˆ"):
                with st.spinner("æ­£åœ¨ç”Ÿæˆçµ±è¨ˆè³‡è¨Š..."):
                    sample_data = generate_fab_sample_data()
                    show_sample_data_preview(sample_data)

def show_sample_data_preview(sample_data: pd.DataFrame):
    """é¡¯ç¤ºç¯„ä¾‹æ•¸æ“šé è¦½å’Œçµ±è¨ˆ"""
    st.subheader("ğŸ“Š ç¯„ä¾‹æ•¸æ“šçµ±è¨ˆé è¦½")
    
    # åŸºæœ¬çµ±è¨ˆ
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ç¸½è³‡æ–™ç­†æ•¸", f"{len(sample_data):,}")
    
    with col2:
        st.metric("FAB æ•¸é‡", sample_data['FAB'].nunique())
    
    with col3:
        st.metric("KPI ç¨®é¡", sample_data['KPI'].nunique())
    
    with col4:
        date_range = (sample_data['REPORT_TIME'].max() - sample_data['REPORT_TIME'].min()).days
        st.metric("æ™‚é–“è·¨åº¦", f"{date_range} å¤©")
    
    # FAB è©³ç´°çµ±è¨ˆ
    st.subheader("ğŸ­ å„ FAB çµ±è¨ˆè³‡è¨Š")
    
    fab_stats = []
    for fab in sample_data['FAB'].unique():
        fab_data = sample_data[sample_data['FAB'] == fab]
        
        # è¨ˆç®—ç•°å¸¸ç‡ï¼ˆç°¡å–®çš„ Z-Score æ–¹æ³•ï¼‰
        anomaly_counts = {}
        for kpi in fab_data['KPI'].unique():
            kpi_values = fab_data[fab_data['KPI'] == kpi]['VALUE'].values
            z_scores = np.abs((kpi_values - np.mean(kpi_values)) / np.std(kpi_values))
            anomaly_counts[kpi] = np.sum(z_scores > 2)
        
        avg_anomaly_rate = np.mean(list(anomaly_counts.values())) / len(fab_data) * fab_data['KPI'].nunique() * 100
        
        fab_stats.append({
            'FAB': fab,
            'KPIæ•¸é‡': fab_data['KPI'].nunique(),
            'è³‡æ–™é»æ•¸': len(fab_data),
            'å¹³å‡ç•°å¸¸ç‡': f"{avg_anomaly_rate:.2f}%",
            'æ™‚é–“ç¯„åœ': f"{fab_data['REPORT_TIME'].min().strftime('%Y-%m')} ~ {fab_data['REPORT_TIME'].max().strftime('%Y-%m')}"
        })
    
    fab_stats_df = pd.DataFrame(fab_stats)
    st.dataframe(fab_stats_df)
    
    # KPI æ•¸å€¼ç¯„åœçµ±è¨ˆ
    st.subheader("ğŸ“ˆ å„ KPI æ•¸å€¼ç¯„åœ")
    
    kpi_stats = []
    for kpi in sample_data['KPI'].unique():
        kpi_data = sample_data[sample_data['KPI'] == kpi]['VALUE']
        
        kpi_stats.append({
            'KPI': kpi,
            'æœ€å°å€¼': f"{kpi_data.min():.2f}",
            'æœ€å¤§å€¼': f"{kpi_data.max():.2f}",
            'å¹³å‡å€¼': f"{kpi_data.mean():.2f}",
            'æ¨™æº–å·®': f"{kpi_data.std():.2f}",
            'è³‡æ–™é»æ•¸': len(kpi_data)
        })
    
    kpi_stats_df = pd.DataFrame(kpi_stats)
    st.dataframe(kpi_stats_df)
    
    # ç‰¹æ®Šäº‹ä»¶æ™‚é–“ç·š
    st.subheader("âš¡ ç‰¹æ®Šäº‹ä»¶æ™‚é–“ç·š")
    
    events_info = [
        {'æ—¥æœŸ': '2023-03-15', 'äº‹ä»¶': 'è¨­å‚™æ•…éšœ', 'é¡å‹': 'è² é¢', 'æŒçºŒå¤©æ•¸': 7},
        {'æ—¥æœŸ': '2023-06-20', 'äº‹ä»¶': 'è£½ç¨‹æ”¹å–„', 'é¡å‹': 'æ­£é¢', 'æŒçºŒå¤©æ•¸': 30},
        {'æ—¥æœŸ': '2023-09-10', 'äº‹ä»¶': 'åŸæ–™çŸ­ç¼º', 'é¡å‹': 'è² é¢', 'æŒçºŒå¤©æ•¸': 14},
        {'æ—¥æœŸ': '2024-02-01', 'äº‹ä»¶': 'æ–°é…æ–¹å°å…¥', 'é¡å‹': 'æ··åˆ', 'æŒçºŒå¤©æ•¸': 21},
        {'æ—¥æœŸ': '2024-07-15', 'äº‹ä»¶': 'è¨­å‚™ç¶­è­·', 'é¡å‹': 'è² é¢', 'æŒçºŒå¤©æ•¸': 3},
        {'æ—¥æœŸ': '2024-10-01', 'äº‹ä»¶': 'ç”¢èƒ½æ“´å……', 'é¡å‹': 'æ­£é¢', 'æŒçºŒå¤©æ•¸': 45}
    ]
    
    events_df = pd.DataFrame(events_info)
    
    # ç”¨é¡è‰²æ¨™ç¤ºä¸åŒé¡å‹çš„äº‹ä»¶
    def color_event_type(val):
        if val == 'æ­£é¢':
            return 'background-color: #d4edda'
        elif val == 'è² é¢':
            return 'background-color: #f8d7da'
        else:
            return 'background-color: #fff3cd'
    
    styled_events = events_df.style.applymap(color_event_type, subset=['é¡å‹'])
    st.dataframe(styled_events)
    
    # ç°¡å–®çš„ KPI è¶¨å‹¢åœ–
    st.subheader("ğŸ“Š ä¸»è¦ KPI è¶¨å‹¢é è¦½")
    
    # é¸æ“‡ä¸€å€‹ FAB å’Œå¹¾å€‹ä¸»è¦ KPI åšé è¦½
    preview_fab = sample_data['FAB'].iloc[0]
    main_kpis = ['Yield', 'Throughput', 'Defect_Rate', 'Equipment_Utilization']
    
    fab_preview_data = sample_data[sample_data['FAB'] == preview_fab]
    
    # è½‰æ›ç‚ºé€è¦–è¡¨æ ¼å¼
    pivot_preview = fab_preview_data[fab_preview_data['KPI'].isin(main_kpis)].pivot_table(
        index=to_plotly_list('REPORT_TIME'), columns='KPI', values=to_plotly_list('VALUE'), aggfunc='mean'
    ).reset_index()
    
    if not pivot_preview.empty:
        fig = go.Figure()
        
        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']
        
        for i, kpi in enumerate(main_kpis):
            if kpi in pivot_preview.columns:
                fig.add_trace(go.Scatter(
                    x=to_plotly_list(pivot_preview['REPORT_TIME']), y=to_plotly_list(pivot_preview[kpi]),
                    mode='lines',
                    name=kpi,
                    line=dict(color=colors[i % len(colors)], width=1.5)
                ))
        
        fig.update_layout(
            title=f"{preview_fab} - ä¸»è¦ KPI è¶¨å‹¢é è¦½",
            xaxis_title="æ™‚é–“",
            yaxis_title="æ•¸å€¼",
            hovermode='x unified',
            height=400,
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=to_plotly_list(1.02),
                xanchor="right",
                x=to_plotly_list(1
            ))
        )
        
        st.plotly_chart(fig)
    
    st.info("ğŸ’¡ ä»¥ä¸Šç‚ºç¯„ä¾‹æ•¸æ“šçš„çµ±è¨ˆé è¦½ã€‚é»æ“Šã€Œè¼‰å…¥ç¯„ä¾‹æ•¸æ“šã€é–‹å§‹é€²è¡Œå®Œæ•´åˆ†æï¼")

def show_fab_characteristics(selected_fab: str):
    """é¡¯ç¤ºç¯„ä¾‹ FAB çš„ç‰¹æ€§èªªæ˜"""
    fab_info = {
        'FAB12A': {
            'tech_node': '28nm',
            'maturity': 'æˆç†Ÿè£½ç¨‹',
            'stability': 'é«˜ç©©å®šæ€§',
            'description': 'æˆç†Ÿçš„28nmè£½ç¨‹å» ï¼Œå…·æœ‰é«˜ç©©å®šæ€§å’Œå„ªç•°çš„è‰¯ç‡è¡¨ç¾',
            'characteristics': ['ä½è®Šç•°æ€§', 'ç©©å®šç”¢èƒ½', 'æˆç†Ÿå·¥è—'],
            'color': '#28a745'
        },
        'FAB14B': {
            'tech_node': '14nm',
            'maturity': 'é‡ç”¢çˆ¬å¡',
            'stability': 'ä¸­ç­‰ç©©å®šæ€§',
            'description': '14nmè£½ç¨‹å» æ­£åœ¨é‡ç”¢çˆ¬å¡éšæ®µï¼Œæ•ˆèƒ½æŒçºŒå„ªåŒ–ä¸­',
            'characteristics': ['ä¸­ç­‰è®Šç•°æ€§', 'æˆé•·ä¸­ç”¢èƒ½', 'å­¸ç¿’æ›²ç·š'],
            'color': '#ffc107'
        },
        'FAB16': {
            'tech_node': '16nm',
            'maturity': 'æˆç†Ÿè£½ç¨‹',
            'stability': 'é«˜ç©©å®šæ€§',
            'description': 'ç©©å®šçš„16nmè£½ç¨‹å» ï¼Œå¹³è¡¡äº†æ•ˆèƒ½èˆ‡æˆæœ¬',
            'characteristics': ['ç©©å®šè¡¨ç¾', 'å¹³è¡¡æˆæœ¬', 'å¯é å·¥è—'],
            'color': '#17a2b8'
        },
        'FAB18': {
            'tech_node': '7nm',
            'maturity': 'æ–°è£½ç¨‹',
            'stability': 'è¼ƒä½ç©©å®šæ€§',
            'description': 'æœ€å…ˆé€²çš„7nmè£½ç¨‹å» ï¼Œä»åœ¨å·¥è—å„ªåŒ–å’Œç©©å®šåŒ–éšæ®µ',
            'characteristics': ['é«˜è®Šç•°æ€§', 'æŠ€è¡“æŒ‘æˆ°', 'å‰µæ–°å·¥è—'],
            'color': '#dc3545'
        }
    }
    
    if selected_fab in fab_info:
        info = fab_info[selected_fab]
        
        st.info(f"""
        **ğŸ­ {selected_fab} ç‰¹æ€§èªªæ˜**
        
        **ğŸ”§ è£½ç¨‹ç¯€é»:** {info['tech_node']}  
        **ğŸ“Š æˆç†Ÿåº¦:** {info['maturity']}  
        **âš¡ ç©©å®šæ€§:** {info['stability']}
        
        **ğŸ“ æè¿°:** {info['description']}
        
        **ğŸ¯ ä¸»è¦ç‰¹å¾µ:** {' â€¢ '.join(info['characteristics'])}
        """)

def calculate_data_quality_score(fab_data: pd.DataFrame) -> float:
    """è¨ˆç®—è³‡æ–™å“è³ªè©•åˆ† (0-10)"""
    score = 10.0
    
    # æª¢æŸ¥ç¼ºå¤±å€¼
    missing_ratio = fab_data['VALUE'].isnull().sum() / len(fab_data)
    score -= missing_ratio * 3
    
    # æª¢æŸ¥ç•°å¸¸å€¼æ¯”ä¾‹
    total_outliers = 0
    total_points = 0
    
    for kpi in fab_data['KPI'].unique():
        kpi_values = fab_data[fab_data['KPI'] == kpi]['VALUE'].values
        if len(kpi_values) > 0:
            z_scores = np.abs((kpi_values - np.mean(kpi_values)) / np.std(kpi_values))
            outliers = np.sum(z_scores > 3)
            total_outliers += outliers
            total_points += len(kpi_values)
    
    if total_points > 0:
        outlier_ratio = total_outliers / total_points
        score -= outlier_ratio * 30  # ç•°å¸¸å€¼å½±éŸ¿è¼ƒå¤§
    
    # æª¢æŸ¥è³‡æ–™å®Œæ•´æ€§ï¼ˆæ™‚é–“é€£çºŒæ€§ï¼‰
    dates = pd.to_datetime(fab_data['REPORT_TIME']).sort_values()
    expected_days = (dates.max() - dates.min()).days + 1
    actual_days = dates.nunique()
    completeness = actual_days / expected_days
    score -= (1 - completeness) * 2
    
    # æª¢æŸ¥ KPI å¤šæ¨£æ€§
    kpi_diversity = fab_data['KPI'].nunique() / 12  # 12 æ˜¯æœ€å¤§ KPI æ•¸é‡
    if kpi_diversity < 0.5:
        score -= (0.5 - kpi_diversity) * 4
    
    return max(0, min(10, score))

def generate_fab_sample_data():
    """ç”Ÿæˆ FAB KPI ç¯„ä¾‹æ•¸æ“š (ä½¿ç”¨çœŸå¯¦æ•¸æ“šç”Ÿæˆå™¨)"""
    from realistic_data_generator import generate_realistic_fab_sample_data
    return generate_realistic_fab_sample_data()

def generate_old_fab_sample_data():
    """åŸå§‹ FAB KPI ç¯„ä¾‹æ•¸æ“šç”Ÿæˆå™¨ (å‚™ç”¨)"""
    np.random.seed(42)
    
    # åŸºæœ¬è¨­å®š
    fabs = ['FAB12A', 'FAB14B', 'FAB16', 'FAB18']
    kpis = ['Yield', 'Throughput', 'Defect_Rate', 'Equipment_Utilization', 
            'Cycle_Time', 'WIP_Level', 'Cost_Per_Unit', 'Quality_Score', 
            'OEE', 'First_Pass_Yield', 'Rework_Rate', 'Critical_Dimension']
    
    # ç”Ÿæˆå…©å¹´çš„æ—¥è³‡æ–™
    dates = pd.date_range('2023-01-01', '2024-12-31', freq='D')
    
    data_list = []
    
    # ç‚ºä¸åŒ FAB è¨­å®šä¸åŒç‰¹æ€§
    fab_characteristics = {
        'FAB12A': {'maturity': 'mature', 'stability': 'high', 'tech_node': '28nm'},
        'FAB14B': {'maturity': 'ramping', 'stability': 'medium', 'tech_node': '14nm'},  
        'FAB16': {'maturity': 'mature', 'stability': 'high', 'tech_node': '16nm'},
        'FAB18': {'maturity': 'new', 'stability': 'low', 'tech_node': '7nm'}
    }
    
    # æ·»åŠ ç‰¹æ®Šäº‹ä»¶å½±éŸ¿
    special_events = {
        '2023-03-15': {'type': 'equipment_down', 'impact': 'negative', 'duration': 7},
        '2023-06-20': {'type': 'process_improvement', 'impact': 'positive', 'duration': 30},
        '2023-09-10': {'type': 'material_shortage', 'impact': 'negative', 'duration': 14},
        '2024-02-01': {'type': 'new_recipe', 'impact': 'mixed', 'duration': 21},
        '2024-07-15': {'type': 'maintenance', 'impact': 'negative', 'duration': 3},
        '2024-10-01': {'type': 'capacity_expansion', 'impact': 'positive', 'duration': 45}
    }
    
    for fab in fabs:
        fab_char = fab_characteristics[fab]
        
        for kpi in kpis:
            # ç‚ºæ¯å€‹ FAB-KPI çµ„åˆç”Ÿæˆä¸åŒç‰¹æ€§çš„æ•¸æ“š
            base_values = generate_enhanced_kpi_data(
                kpi, len(dates), fab, fab_char, dates, special_events
            )
            
            for i, date in enumerate(dates):
                data_list.append({
                    'FAB': fab,
                    'KPI': kpi,
                    'REPORT_TIME': date,
                    'VALUE': base_values[i]
                })
    
    return pd.DataFrame(data_list)

def generate_enhanced_kpi_data(kpi: str, length: int, fab: str, fab_char: dict, 
                              dates: pd.DatetimeIndex, special_events: dict) -> np.ndarray:
    """ç”Ÿæˆå¢å¼·çš„ KPI æ™‚åºè³‡æ–™ï¼ŒåŒ…å« FAB ç‰¹æ€§å’Œç‰¹æ®Šäº‹ä»¶"""
    np.random.seed(hash(kpi + fab) % 2147483647)
    
    # æ ¹æ“š FAB æˆç†Ÿåº¦èª¿æ•´åŸºç¤åƒæ•¸
    stability_factor = {'high': 0.3, 'medium': 0.6, 'low': 1.0}[fab_char['stability']]
    maturity_factor = {'mature': 1.0, 'ramping': 0.85, 'new': 0.7}[fab_char['maturity']]
    
    if kpi == 'Yield':
        base = (94 - 2 * (1 - maturity_factor)) + np.random.randn() * stability_factor
        trend = np.cumsum(np.random.randn(length) * 0.008 * stability_factor)
        seasonal = 1.5 * np.sin(np.arange(length) * 2 * np.pi / 30)  # æœˆé€±æœŸ
        weekly = 0.8 * np.sin(np.arange(length) * 2 * np.pi / 7)   # é€±é€±æœŸ
        noise = np.random.randn(length) * 0.4 * stability_factor
        values = base + trend + seasonal + weekly + noise
        values = np.clip(values, 82, 98.5)
        
    elif kpi == 'Throughput':
        base = (800 * maturity_factor) + np.random.randn() * 50
        trend = np.cumsum(np.random.randn(length) * 0.3 * stability_factor)
        seasonal = 60 * np.sin(np.arange(length) * 2 * np.pi / 7)  # é€±é€±æœŸ  
        monthly = 30 * np.sin(np.arange(length) * 2 * np.pi / 30)  # æœˆé€±æœŸ
        noise = np.random.randn(length) * 15 * stability_factor
        values = base + trend + seasonal + monthly + noise
        values = np.clip(values, 100, 1500)
        
    elif kpi == 'Defect_Rate':
        base = (1.0 + 1.5 * (1 - maturity_factor)) + np.random.randn() * 0.2
        trend = np.cumsum(np.random.randn(length) * 0.002 * stability_factor)
        seasonal = 0.15 * np.sin(np.arange(length) * 2 * np.pi / 14)  # é›™é€±é€±æœŸ
        noise = np.random.randn(length) * 0.08 * stability_factor
        values = base + trend + seasonal + noise
        values = np.clip(values, 0.1, 6.0)
        
    elif kpi == 'Equipment_Utilization':
        base = (90 * maturity_factor) + np.random.randn() * 2
        trend = np.cumsum(np.random.randn(length) * 0.008 * stability_factor)
        seasonal = 4 * np.sin(np.arange(length) * 2 * np.pi / 7)  # é€±é€±æœŸ
        noise = np.random.randn(length) * 1.2 * stability_factor
        values = base + trend + seasonal + noise
        values = np.clip(values, 65, 98)
        
    elif kpi == 'Cycle_Time':
        base = (40 + 15 * (1 - maturity_factor)) + np.random.randn() * 3
        trend = np.cumsum(np.random.randn(length) * 0.015 * stability_factor)
        seasonal = 4 * np.sin(np.arange(length) * 2 * np.pi / 30)  # æœˆé€±æœŸ
        noise = np.random.randn(length) * 1.8 * stability_factor
        values = base + trend + seasonal + noise
        values = np.clip(values, 20, 85)
        
    elif kpi == 'WIP_Level':
        base = (3000 * maturity_factor) + np.random.randn() * 150
        trend = np.cumsum(np.random.randn(length) * 1.5 * stability_factor)
        seasonal = 250 * np.sin(np.arange(length) * 2 * np.pi / 30)  # æœˆé€±æœŸ
        noise = np.random.randn(length) * 40 * stability_factor
        values = base + trend + seasonal + noise
        values = np.clip(values, 800, 6500)
        
    elif kpi == 'Cost_Per_Unit':
        base = (100 + 30 * (1 - maturity_factor)) + np.random.randn() * 8
        trend = np.cumsum(np.random.randn(length) * 0.04 * stability_factor)
        seasonal = 6 * np.sin(np.arange(length) * 2 * np.pi / 90)  # å­£åº¦é€±æœŸ
        noise = np.random.randn(length) * 2.5 * stability_factor
        values = base + trend + seasonal + noise
        values = np.clip(values, 50, 220)
        
    elif kpi == 'Quality_Score':
        base = (92 * maturity_factor) + np.random.randn() * 2
        trend = np.cumsum(np.random.randn(length) * 0.004 * stability_factor)
        seasonal = 1.5 * np.sin(np.arange(length) * 2 * np.pi / 30)  # æœˆé€±æœŸ
        noise = np.random.randn(length) * 0.8 * stability_factor
        values = base + trend + seasonal + noise
        values = np.clip(values, 70, 100)
        
    elif kpi == 'OEE':  # Overall Equipment Effectiveness
        base = (85 * maturity_factor) + np.random.randn() * 3
        trend = np.cumsum(np.random.randn(length) * 0.01 * stability_factor)
        seasonal = 3 * np.sin(np.arange(length) * 2 * np.pi / 7)  # é€±é€±æœŸ
        noise = np.random.randn(length) * 1.5 * stability_factor
        values = base + trend + seasonal + noise
        values = np.clip(values, 60, 95)
        
    elif kpi == 'First_Pass_Yield':
        base = (89 * maturity_factor) + np.random.randn() * 2.5
        trend = np.cumsum(np.random.randn(length) * 0.006 * stability_factor)
        seasonal = 2 * np.sin(np.arange(length) * 2 * np.pi / 30)  # æœˆé€±æœŸ
        noise = np.random.randn(length) * 1.2 * stability_factor
        values = base + trend + seasonal + noise
        values = np.clip(values, 75, 98)
        
    elif kpi == 'Rework_Rate':
        base = (3.0 + 2.0 * (1 - maturity_factor)) + np.random.randn() * 0.4
        trend = np.cumsum(np.random.randn(length) * 0.003 * stability_factor)
        seasonal = 0.3 * np.sin(np.arange(length) * 2 * np.pi / 14)  # é›™é€±é€±æœŸ
        noise = np.random.randn(length) * 0.15 * stability_factor
        values = base + trend + seasonal + noise
        values = np.clip(values, 0.5, 12.0)
        
    elif kpi == 'Critical_Dimension':  # CD uniformity (nm)
        base = (2.5 + 1.0 * (1 - maturity_factor)) + np.random.randn() * 0.3
        trend = np.cumsum(np.random.randn(length) * 0.002 * stability_factor)
        seasonal = 0.2 * np.sin(np.arange(length) * 2 * np.pi / 7)  # é€±é€±æœŸ
        noise = np.random.randn(length) * 0.1 * stability_factor
        values = base + trend + seasonal + noise
        values = np.clip(values, 1.0, 8.0)
    
    else:
        # é è¨­å€¼
        values = 100 + np.cumsum(np.random.randn(length) * 0.5 * stability_factor)
    
    # æ‡‰ç”¨ç‰¹æ®Šäº‹ä»¶å½±éŸ¿
    values = apply_special_events(values, dates, special_events, kpi, fab_char)
    
    # æ·»åŠ éš¨æ©Ÿç•°å¸¸å€¼ï¼ˆæ ¹æ“š FAB ç©©å®šæ€§èª¿æ•´ï¼‰
    outlier_prob = 0.015 * stability_factor  # ç©©å®šæ€§ä½çš„ FAB ç•°å¸¸æ›´å¤š
    outliers = np.random.random(length) < outlier_prob
    
    # ä¸åŒé¡å‹çš„ç•°å¸¸
    outlier_types = np.random.choice(['spike', 'dip', 'shift'], size=np.sum(outliers))
    outlier_indices = np.where(outliers)[0]
    
    for i, outlier_type in enumerate(outlier_types):
        idx = outlier_indices[i]
        if outlier_type == 'spike':
            values[idx] *= 1 + np.random.uniform(0.2, 0.8)
        elif outlier_type == 'dip':
            values[idx] *= 1 - np.random.uniform(0.15, 0.6)
        elif outlier_type == 'shift':
            # é€£çºŒå¹¾å¤©çš„åç§»
            shift_duration = np.random.randint(2, 8)
            shift_magnitude = np.random.uniform(-0.3, 0.3)
            end_idx = min(idx + shift_duration, length)
            values[idx:end_idx] *= (1 + shift_magnitude)
    
    return values

def apply_special_events(values: np.ndarray, dates: pd.DatetimeIndex, 
                        special_events: dict, kpi: str, fab_char: dict) -> np.ndarray:
    """æ‡‰ç”¨ç‰¹æ®Šäº‹ä»¶å° KPI çš„å½±éŸ¿"""
    values_modified = values.copy()
    
    for event_date_str, event_info in special_events.items():
        event_date = pd.to_datetime(event_date_str)
        
        # æ‰¾åˆ°äº‹ä»¶é–‹å§‹çš„ç´¢å¼•
        try:
            start_idx = dates.get_loc(event_date)
        except KeyError:
            continue
            
        end_idx = min(start_idx + event_info['duration'], len(values))
        
        # æ ¹æ“šäº‹ä»¶é¡å‹å’Œ KPI è¨ˆç®—å½±éŸ¿
        impact_magnitude = calculate_event_impact(event_info, kpi, fab_char)
        
        if impact_magnitude != 0:
            # æ‡‰ç”¨æ¼¸é€²å¼å½±éŸ¿ï¼ˆäº‹ä»¶é–‹å§‹æ™‚å½±éŸ¿æœ€å¤§ï¼Œé€æ¼¸æ¢å¾©ï¼‰
            for i in range(start_idx, end_idx):
                decay_factor = 1 - (i - start_idx) / event_info['duration']
                values_modified[i] *= (1 + impact_magnitude * decay_factor)
    
    return values_modified

def calculate_event_impact(event_info: dict, kpi: str, fab_char: dict) -> float:
    """è¨ˆç®—ç‰¹æ®Šäº‹ä»¶å°ç‰¹å®š KPI çš„å½±éŸ¿ç¨‹åº¦"""
    event_type = event_info['type']
    impact_direction = event_info['impact']
    
    # åŸºç¤å½±éŸ¿ç¨‹åº¦
    base_impacts = {
        'equipment_down': {
            'Yield': -0.15, 'Throughput': -0.25, 'Defect_Rate': 0.3,
            'Equipment_Utilization': -0.20, 'OEE': -0.18, 'Cycle_Time': 0.15
        },
        'process_improvement': {
            'Yield': 0.08, 'First_Pass_Yield': 0.10, 'Defect_Rate': -0.20,
            'Quality_Score': 0.12, 'Rework_Rate': -0.25, 'Cost_Per_Unit': -0.05
        },
        'material_shortage': {
            'Throughput': -0.18, 'WIP_Level': -0.15, 'Cycle_Time': 0.20,
            'Cost_Per_Unit': 0.08, 'Equipment_Utilization': -0.12
        },
        'new_recipe': {
            'Yield': -0.05, 'Defect_Rate': 0.15, 'Cycle_Time': 0.10,
            'First_Pass_Yield': -0.08, 'Critical_Dimension': 0.12
        },
        'maintenance': {
            'Equipment_Utilization': -0.30, 'Throughput': -0.20, 'OEE': -0.25,
            'Cycle_Time': 0.15
        },
        'capacity_expansion': {
            'Throughput': 0.15, 'WIP_Level': 0.20, 'Equipment_Utilization': 0.10,
            'Cost_Per_Unit': -0.08
        }
    }
    
    # æ ¹æ“š FAB æˆç†Ÿåº¦èª¿æ•´å½±éŸ¿ç¨‹åº¦
    maturity_multiplier = {'mature': 0.7, 'ramping': 1.0, 'new': 1.3}[fab_char['maturity']]
    
    base_impact = base_impacts.get(event_type, {}).get(kpi, 0)
    
    return base_impact * maturity_multiplier

def statistical_detection_page():
    st.header("ğŸ“Š çµ±è¨ˆæ–¹æ³•ç•°å¸¸åµæ¸¬")
    
    if st.session_state.fab_data is None:
        st.warning("âš ï¸ è«‹å…ˆä¸Šå‚³æ•¸æ“šä¸¦é¸æ“‡ FAB")
        st.info("ğŸ’¡ è«‹å…ˆå¾å·¦å´é¸å–®é¸æ“‡ã€ŒKPI å¿«é€Ÿåˆ†æã€è¼‰å…¥æ•¸æ“š")
        return
    
    fab_data = st.session_state.fab_data
    selected_fab = st.session_state.selected_fab
    available_kpis = st.session_state.available_kpis
    
    # é¡¯ç¤ºç•¶å‰é¸æ“‡
    st.info(f"ğŸ­ ç•¶å‰ FAB: **{selected_fab}** | ğŸ“Š ç•¶å‰ KPI: **{st.session_state.selected_kpi}**")
    
    st.subheader("âš™ï¸ åµæ¸¬åƒæ•¸è¨­å®š")
    
    col1, col2 = st.columns(2)
    
    with col1:
        detection_method = st.selectbox(
            "é¸æ“‡çµ±è¨ˆæ–¹æ³•:",
            ["Z-Score", "IQR (å››åˆ†ä½è·)", "Modified Z-Score"]
        )
    
    with col2:
        if detection_method == "Z-Score" or detection_method == "Modified Z-Score":
            threshold = st.slider(
                "ç•°å¸¸é–¾å€¼ (æ¨™æº–å·®å€æ•¸):", 
                min_value=1.0, max_value=5.0, value=2.0, step=0.1
            )
        else:
            threshold = st.slider(
                "IQR å€æ•¸é–¾å€¼:", 
                min_value=1.0, max_value=3.0, value=1.5, step=0.1
            )
    
    # é è¨­ä½¿ç”¨ç•¶å‰é¸æ“‡çš„ KPIï¼Œä½†å…è¨±åˆ‡æ›
    current_kpi_index = available_kpis.index(st.session_state.selected_kpi) if st.session_state.selected_kpi in available_kpis else 0
    selected_kpi = st.selectbox(
        "é¸æ“‡è¦åˆ†æçš„ KPI:",
        options=available_kpis,
        index=to_plotly_list(current_kpi_index
    ))
    
    # æ›´æ–° session state
    if selected_kpi != st.session_state.selected_kpi:
        st.session_state.selected_kpi = selected_kpi
    
    if st.button("ğŸ” åŸ·è¡Œç•°å¸¸åµæ¸¬"):
        # è½‰æ›è³‡æ–™æ ¼å¼
        kpi_data = fab_data[fab_data['KPI'] == selected_kpi].copy()
        kpi_data = kpi_data.sort_values('REPORT_TIME')
        
        if len(kpi_data) == 0:
            st.error("âŒ æ‰€é¸ KPI ç„¡è³‡æ–™")
            return
            
        outliers_info = detect_statistical_outliers_fab(kpi_data, detection_method, threshold)
        
        st.subheader("ğŸ“ˆ æ™‚åºåœ–èˆ‡ç•°å¸¸é»")
        
        # Create visualization with matplotlib
        dates = pd.to_datetime(kpi_data['REPORT_TIME'])
        values = kpi_data['VALUE'].values
        anomalies = outliers_info['outlier_indices']
        scores = outliers_info['scores']
        
        if detection_method == "Z-Score" or detection_method == "Modified Z-Score":
            fig = create_zscore_analysis_plot(
                dates=dates,
                values=values,
                z_scores=scores,
                threshold=threshold,
                outliers=anomalies,
                title=f"{selected_fab} - {selected_kpi}"
            )
        elif detection_method == "IQR (å››åˆ†ä½è·)":
            fig = create_iqr_analysis_plot(
                dates=dates,
                values=values,
                outliers=anomalies,
                iqr_multiplier=threshold,
                title=f"{selected_fab} - {selected_kpi}"
            )
        else:
            # Fallback to general anomaly plot
            fig = create_anomaly_plot(
                dates=dates,
                values=values,
                anomalies=anomalies,
                title=f"{selected_fab} - {selected_kpi}",
                method=detection_method,
                scores=scores,
                threshold=threshold
            )
        
        render_matplotlib_figure(fig)
        
        # Show statistics
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ç¸½æ•¸æ“šé»", len(kpi_data))
        
        with col2:
            st.metric("ç•°å¸¸é»æ•¸é‡", len(outliers_info['outlier_indices']))
        
        with col3:
            anomaly_rate = len(outliers_info['outlier_indices']) / len(kpi_data) * 100
            st.metric("ç•°å¸¸ç‡", f"{anomaly_rate:.2f}%")
        
        # Show outlier details
        if len(outliers_info['outlier_indices']) > 0:
            st.subheader("ğŸ” ç•°å¸¸é»è©³ç´°è³‡è¨Š")
            
            outlier_df = kpi_data.iloc[outliers_info['outlier_indices']].copy()
            outlier_df['ç•°å¸¸ç¨‹åº¦'] = outliers_info['scores'][outliers_info['outlier_indices']]
            outlier_df = outlier_df.sort_values('ç•°å¸¸ç¨‹åº¦', ascending=False)
            
            st.dataframe(outlier_df[['REPORT_TIME', 'VALUE', 'ç•°å¸¸ç¨‹åº¦']])
        else:
            st.success("âœ… æœªç™¼ç¾ç•°å¸¸é»")

def detect_statistical_outliers_fab(kpi_data, method, threshold):
    """é©ç”¨æ–¼ FAB è³‡æ–™çµæ§‹çš„çµ±è¨ˆç•°å¸¸åµæ¸¬"""
    data = kpi_data['VALUE'].values
    
    if method == "Z-Score":
        mean_val = np.mean(data)
        std_val = np.std(data)
        z_scores = np.abs((data - mean_val) / std_val)
        outlier_mask = z_scores > threshold
        scores = z_scores
        
    elif method == "Modified Z-Score":
        median_val = np.median(data)
        mad = np.median(np.abs(data - median_val))
        modified_z_scores = 0.6745 * (data - median_val) / mad
        outlier_mask = np.abs(modified_z_scores) > threshold
        scores = np.abs(modified_z_scores)
        mean_val = median_val
        std_val = mad
        
    elif method == "IQR (å››åˆ†ä½è·)":
        Q1 = np.percentile(data, 25)
        Q3 = np.percentile(data, 75)
        IQR = Q3 - Q1
        lower_bound = Q1 - threshold * IQR
        upper_bound = Q3 + threshold * IQR
        outlier_mask = (data < lower_bound) | (data > upper_bound)
        scores = np.maximum((Q1 - data) / IQR, (data - Q3) / IQR)
        mean_val = np.median(data)
        std_val = IQR
    
    outlier_indices = np.where(outlier_mask)[0]
    
    return {
        'outlier_indices': outlier_indices,
        'scores': scores,
        'mean': mean_val,
        'std': std_val
    }

def detect_statistical_outliers(df, kpi_column, date_column, method, threshold):
    data = df[kpi_column].values
    
    if method == "Z-Score":
        mean_val = np.mean(data)
        std_val = np.std(data)
        z_scores = np.abs((data - mean_val) / std_val)
        outlier_mask = z_scores > threshold
        scores = z_scores
        
    elif method == "Modified Z-Score":
        median_val = np.median(data)
        mad = np.median(np.abs(data - median_val))
        modified_z_scores = 0.6745 * (data - median_val) / mad
        outlier_mask = np.abs(modified_z_scores) > threshold
        scores = np.abs(modified_z_scores)
        mean_val = median_val
        std_val = mad
        
    elif method == "IQR (å››åˆ†ä½è·)":
        Q1 = np.percentile(data, 25)
        Q3 = np.percentile(data, 75)
        IQR = Q3 - Q1
        lower_bound = Q1 - threshold * IQR
        upper_bound = Q3 + threshold * IQR
        outlier_mask = (data < lower_bound) | (data > upper_bound)
        scores = np.maximum((Q1 - data) / IQR, (data - Q3) / IQR)
        mean_val = np.median(data)
        std_val = IQR
    
    outlier_indices = np.where(outlier_mask)[0]
    
    return {
        'outlier_indices': outlier_indices,
        'scores': scores,
        'mean': mean_val,
        'std': std_val
    }

def moving_average_detection_page():
    st.header("ğŸ“ˆ ç§»å‹•å¹³å‡ç•°å¸¸åµæ¸¬")
    
    if st.session_state.fab_data is None:
        st.warning("âš ï¸ è«‹å…ˆä¸Šå‚³æ•¸æ“šä¸¦é¸æ“‡ FAB")
        st.info("ğŸ’¡ è«‹å…ˆå¾å·¦å´é¸å–®é¸æ“‡ã€ŒKPI å¿«é€Ÿåˆ†æã€è¼‰å…¥æ•¸æ“š")
        return
    
    fab_data = st.session_state.fab_data
    selected_fab = st.session_state.selected_fab
    available_kpis = st.session_state.available_kpis
    
    # é¡¯ç¤ºç•¶å‰é¸æ“‡
    st.info(f"ğŸ­ ç•¶å‰ FAB: **{selected_fab}** | ğŸ“Š ç•¶å‰ KPI: **{st.session_state.selected_kpi}**")
    
    st.subheader("âš™ï¸ ç§»å‹•å¹³å‡åƒæ•¸è¨­å®š")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        ma_method = st.selectbox(
            "ç§»å‹•å¹³å‡æ–¹æ³•:",
            ["ç°¡å–®ç§»å‹•å¹³å‡ (SMA)", "æŒ‡æ•¸ç§»å‹•å¹³å‡ (EMA)", "æ»¾å‹•æ¨™æº–å·®åµæ¸¬"]
        )
    
    with col2:
        window_size = st.slider(
            "çª—å£å¤§å° (å¤©):", 
            min_value=3, max_value=90, value=30, step=1
        )
    
    with col3:
        if ma_method == "æ»¾å‹•æ¨™æº–å·®åµæ¸¬":
            threshold = st.slider(
                "æ¨™æº–å·®å€æ•¸é–¾å€¼:", 
                min_value=1.0, max_value=5.0, value=2.0, step=0.1
            )
        else:
            threshold = st.slider(
                "åé›¢é–¾å€¼ (%):", 
                min_value=5.0, max_value=50.0, value=15.0, step=1.0
            )
    
    # é è¨­ä½¿ç”¨ç•¶å‰é¸æ“‡çš„ KPIï¼Œä½†å…è¨±åˆ‡æ›
    current_kpi_index = available_kpis.index(st.session_state.selected_kpi) if st.session_state.selected_kpi in available_kpis else 0
    selected_kpi = st.selectbox(
        "é¸æ“‡è¦åˆ†æçš„ KPI:",
        options=available_kpis,
        index=to_plotly_list(current_kpi_index
    ))
    
    # æ›´æ–° session state
    if selected_kpi != st.session_state.selected_kpi:
        st.session_state.selected_kpi = selected_kpi
    
    if st.button("ğŸ” åŸ·è¡Œç§»å‹•å¹³å‡åµæ¸¬"):
        # è½‰æ›è³‡æ–™æ ¼å¼
        kpi_data = fab_data[fab_data['KPI'] == selected_kpi].copy()
        kpi_data = kpi_data.sort_values('REPORT_TIME')
        
        if len(kpi_data) == 0:
            st.error("âŒ æ‰€é¸ KPI ç„¡è³‡æ–™")
            return
            
        outliers_info = detect_moving_average_outliers_fab(
            kpi_data, ma_method, window_size, threshold
        )
        
        st.subheader("ğŸ“ˆ æ™‚åºåœ–èˆ‡ç§»å‹•å¹³å‡ç·š")
        
        # Create visualization
        fig = go.Figure()
        
        # Add original data
        fig.add_trace(go.Scatter(
            x=to_plotly_list(kpi_data['REPORT_TIME']), y=to_plotly_list(kpi_data['VALUE']),
            mode='lines+markers',
            name='åŸå§‹æ•¸æ“š',
            line=dict(color='blue', width=2),
            marker=dict(size=4)
        ))
        
        # Add moving average
        fig.add_trace(go.Scatter(
            x=to_plotly_list(kpi_data['REPORT_TIME']), y=to_plotly_list(outliers_info['moving_avg']),
            mode='lines',
            name=f'{ma_method} (çª—å£={window_size})',
            line=dict(color='green', width=2)
        ))
        
        # Add upper and lower bounds
        if 'upper_bound' in outliers_info:
            fig.add_trace(go.Scatter(
                x=to_plotly_list(kpi_data['REPORT_TIME']), y=to_plotly_list(outliers_info['upper_bound']),
                mode='lines',
                name='ä¸Šç•Œ',
                line=dict(color='orange', dash='dash')
            ))
            
            fig.add_trace(go.Scatter(
                x=to_plotly_list(kpi_data['REPORT_TIME']), y=to_plotly_list(outliers_info['lower_bound']),
                mode='lines',
                name='ä¸‹ç•Œ',
                line=dict(color='orange', dash='dash')
            ))
        
        # Add outliers
        if len(outliers_info['outlier_indices']) > 0:
            outlier_dates = kpi_data.iloc[outliers_info['outlier_indices']]['REPORT_TIME']
            outlier_values = kpi_data.iloc[outliers_info['outlier_indices']]['VALUE']
            
            fig.add_trace(go.Scatter(
                x=to_plotly_list(outlier_dates), y=to_plotly_list(outlier_values),
                mode='markers',
                name='ç•°å¸¸é»',
                marker=dict(color='red', size=10, symbol='x')
            ))
        
        fig.update_layout(
            title=f"{selected_fab} - {selected_kpi} - {ma_method} ç•°å¸¸åµæ¸¬",
            xaxis_title="å ±å‘Šæ™‚é–“",
            yaxis_title="æ•¸å€¼",
            hovermode='x unified',
            height=600
        )
        
        st.plotly_chart(fig)
        
        # Show statistics
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ç¸½æ•¸æ“šé»", len(kpi_data))
        
        with col2:
            st.metric("ç•°å¸¸é»æ•¸é‡", len(outliers_info['outlier_indices']))
        
        with col3:
            anomaly_rate = len(outliers_info['outlier_indices']) / len(kpi_data) * 100
            st.metric("ç•°å¸¸ç‡", f"{anomaly_rate:.2f}%")
        
        # Show outlier details
        if len(outliers_info['outlier_indices']) > 0:
            st.subheader("ğŸ” ç•°å¸¸é»è©³ç´°è³‡è¨Š")
            
            outlier_df = kpi_data.iloc[outliers_info['outlier_indices']].copy()
            outlier_df['ç§»å‹•å¹³å‡å€¼'] = outliers_info['moving_avg'][outliers_info['outlier_indices']]
            outlier_df['åé›¢ç¨‹åº¦'] = outliers_info['deviations'][outliers_info['outlier_indices']]
            outlier_df = outlier_df.sort_values('åé›¢ç¨‹åº¦', ascending=False)
            
            st.dataframe(outlier_df[['REPORT_TIME', 'VALUE', 'ç§»å‹•å¹³å‡å€¼', 'åé›¢ç¨‹åº¦']])
        else:
            st.success("âœ… æœªç™¼ç¾ç•°å¸¸é»")

def detect_moving_average_outliers_fab(kpi_data, method, window_size, threshold):
    """é©ç”¨æ–¼ FAB è³‡æ–™çµæ§‹çš„ç§»å‹•å¹³å‡ç•°å¸¸åµæ¸¬"""
    data = kpi_data['VALUE'].values
    
    if method == "ç°¡å–®ç§»å‹•å¹³å‡ (SMA)":
        moving_avg = pd.Series(data).rolling(window=window_size, center=False).mean().values
        deviations = np.abs((data - moving_avg) / moving_avg) * 100
        outlier_mask = deviations > threshold
        
        # Calculate bounds for visualization
        upper_bound = moving_avg * (1 + threshold/100)
        lower_bound = moving_avg * (1 - threshold/100)
        
    elif method == "æŒ‡æ•¸ç§»å‹•å¹³å‡ (EMA)":
        ema_series = pd.Series(data).ewm(span=window_size).mean()
        moving_avg = ema_series.values
        deviations = np.abs((data - moving_avg) / moving_avg) * 100
        outlier_mask = deviations > threshold
        
        # Calculate bounds for visualization
        upper_bound = moving_avg * (1 + threshold/100)
        lower_bound = moving_avg * (1 - threshold/100)
        
    elif method == "æ»¾å‹•æ¨™æº–å·®åµæ¸¬":
        rolling_mean = pd.Series(data).rolling(window=window_size, center=False).mean()
        rolling_std = pd.Series(data).rolling(window=window_size, center=False).std()
        
        moving_avg = rolling_mean.values
        upper_bound = (rolling_mean + threshold * rolling_std).values
        lower_bound = (rolling_mean - threshold * rolling_std).values
        
        outlier_mask = (data > upper_bound) | (data < lower_bound)
        deviations = np.maximum(
            (data - upper_bound) / rolling_std.values,
            (lower_bound - data) / rolling_std.values
        )
        deviations = np.nan_to_num(deviations, 0)
    
    # Remove NaN values for first few points
    valid_mask = ~np.isnan(moving_avg)
    outlier_mask = outlier_mask & valid_mask
    
    outlier_indices = np.where(outlier_mask)[0]
    
    result = {
        'outlier_indices': outlier_indices,
        'deviations': deviations,
        'moving_avg': moving_avg
    }
    
    if 'upper_bound' in locals():
        result['upper_bound'] = upper_bound
        result['lower_bound'] = lower_bound
    
    return result

def detect_moving_average_outliers(df, kpi_column, date_column, method, window_size, threshold):
    data = df[kpi_column].values
    
    if method == "ç°¡å–®ç§»å‹•å¹³å‡ (SMA)":
        moving_avg = pd.Series(data).rolling(window=window_size, center=False).mean().values
        deviations = np.abs((data - moving_avg) / moving_avg) * 100
        outlier_mask = deviations > threshold
        
        # Calculate bounds for visualization
        upper_bound = moving_avg * (1 + threshold/100)
        lower_bound = moving_avg * (1 - threshold/100)
        
    elif method == "æŒ‡æ•¸ç§»å‹•å¹³å‡ (EMA)":
        ema_series = pd.Series(data).ewm(span=window_size).mean()
        moving_avg = ema_series.values
        deviations = np.abs((data - moving_avg) / moving_avg) * 100
        outlier_mask = deviations > threshold
        
        # Calculate bounds for visualization
        upper_bound = moving_avg * (1 + threshold/100)
        lower_bound = moving_avg * (1 - threshold/100)
        
    elif method == "æ»¾å‹•æ¨™æº–å·®åµæ¸¬":
        rolling_mean = pd.Series(data).rolling(window=window_size, center=False).mean()
        rolling_std = pd.Series(data).rolling(window=window_size, center=False).std()
        
        moving_avg = rolling_mean.values
        upper_bound = (rolling_mean + threshold * rolling_std).values
        lower_bound = (rolling_mean - threshold * rolling_std).values
        
        outlier_mask = (data > upper_bound) | (data < lower_bound)
        deviations = np.maximum(
            (data - upper_bound) / rolling_std.values,
            (lower_bound - data) / rolling_std.values
        )
        deviations = np.nan_to_num(deviations, 0)
    
    # Remove NaN values for first few points
    valid_mask = ~np.isnan(moving_avg)
    outlier_mask = outlier_mask & valid_mask
    
    outlier_indices = np.where(outlier_mask)[0]
    
    result = {
        'outlier_indices': outlier_indices,
        'deviations': deviations,
        'moving_avg': moving_avg
    }
    
    if 'upper_bound' in locals():
        result['upper_bound'] = upper_bound
        result['lower_bound'] = lower_bound
    
    return result

def seasonal_decomposition_page():
    st.header("ğŸ”„ å­£ç¯€æ€§åˆ†è§£ç•°å¸¸åµæ¸¬")
    
    if st.session_state.fab_data is None:
        st.warning("âš ï¸ è«‹å…ˆä¸Šå‚³æ•¸æ“šä¸¦é¸æ“‡ FAB")
        st.info("ğŸ’¡ è«‹å…ˆå¾å·¦å´é¸å–®é¸æ“‡ã€ŒKPI å¿«é€Ÿåˆ†æã€è¼‰å…¥æ•¸æ“š")
        return
    
    fab_data = st.session_state.fab_data
    selected_fab = st.session_state.selected_fab
    available_kpis = st.session_state.available_kpis
    
    # é¡¯ç¤ºç•¶å‰é¸æ“‡
    st.info(f"ğŸ­ ç•¶å‰ FAB: **{selected_fab}** | ğŸ“Š ç•¶å‰ KPI: **{st.session_state.selected_kpi}**")
    
    st.subheader("âš™ï¸ å­£ç¯€æ€§åˆ†è§£åƒæ•¸è¨­å®š")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        decomposition_model = st.selectbox(
            "åˆ†è§£æ¨¡å‹:",
            ["additive", "multiplicative"],
            format_func=lambda x: "åŠ æ³•æ¨¡å‹" if x == "additive" else "ä¹˜æ³•æ¨¡å‹"
        )
    
    with col2:
        seasonal_period = st.selectbox(
            "å­£ç¯€é€±æœŸ:",
            [7, 30, 90, 365],
            index=to_plotly_list(0),
            format_func=lambda x: f"{x} å¤©"
        )
    
    with col3:
        threshold = st.slider(
            "æ®˜å·®ç•°å¸¸é–¾å€¼ (æ¨™æº–å·®å€æ•¸):", 
            min_value=1.0, max_value=5.0, value=2.5, step=0.1
        )
    
    # é è¨­ä½¿ç”¨ç•¶å‰é¸æ“‡çš„ KPIï¼Œä½†å…è¨±åˆ‡æ›
    current_kpi_index = available_kpis.index(st.session_state.selected_kpi) if st.session_state.selected_kpi in available_kpis else 0
    selected_kpi = st.selectbox(
        "é¸æ“‡è¦åˆ†æçš„ KPI:",
        options=available_kpis,
        index=to_plotly_list(current_kpi_index
    ))
    
    # æ›´æ–° session state
    if selected_kpi != st.session_state.selected_kpi:
        st.session_state.selected_kpi = selected_kpi
    
    if st.button("ğŸ” åŸ·è¡Œå­£ç¯€æ€§åˆ†è§£åµæ¸¬"):
        try:
            # è½‰æ›è³‡æ–™æ ¼å¼
            kpi_data = fab_data[fab_data['KPI'] == selected_kpi].copy()
            kpi_data = kpi_data.sort_values('REPORT_TIME')
            
            if len(kpi_data) == 0:
                st.error("âŒ æ‰€é¸ KPI ç„¡è³‡æ–™")
                return
                
            decomp_result = perform_seasonal_decomposition_fab(
                kpi_data, decomposition_model, seasonal_period, threshold
            )
            
            if decomp_result is None:
                st.error("âŒ æ•¸æ“šé»ä¸è¶³ä»¥é€²è¡Œå­£ç¯€æ€§åˆ†è§£ï¼Œè‡³å°‘éœ€è¦å…©å€‹å®Œæ•´çš„å­£ç¯€é€±æœŸ")
                return
            
            # Show decomposition components
            st.subheader("ğŸ“Š å­£ç¯€æ€§åˆ†è§£çµæœ")
            
            # Create subplots for decomposition
            from plotly.subplots import make_subplots
            
            fig = make_subplots(
                rows=4, cols=1,
                subplot_titles=('åŸå§‹æ•¸æ“š', 'è¶¨å‹¢', 'å­£ç¯€æ€§', 'æ®˜å·®'),
                vertical_spacing=0.08,
                shared_xaxes=True
            )
            
            # Original data
            fig.add_trace(
                go.Scatter(x=to_plotly_list(kpi_data['REPORT_TIME']), y=to_plotly_list(kpi_data['VALUE']), 
                          mode='lines', name='åŸå§‹æ•¸æ“š', line=dict(color='blue')),
                row=1, col=1
            )
            
            # Trend
            fig.add_trace(
                go.Scatter(x=to_plotly_list(kpi_data['REPORT_TIME']), y=to_plotly_list(decomp_result['trend']), 
                          mode='lines', name='è¶¨å‹¢', line=dict(color='green')),
                row=2, col=1
            )
            
            # Seasonal
            fig.add_trace(
                go.Scatter(x=to_plotly_list(kpi_data['REPORT_TIME']), y=to_plotly_list(decomp_result['seasonal']), 
                          mode='lines', name='å­£ç¯€æ€§', line=dict(color='orange')),
                row=3, col=1
            )
            
            # Residuals with outliers
            fig.add_trace(
                go.Scatter(x=to_plotly_list(kpi_data['REPORT_TIME']), y=to_plotly_list(decomp_result['resid']), 
                          mode='lines', name='æ®˜å·®', line=dict(color='gray')),
                row=4, col=1
            )
            
            # Add outliers to residual plot
            if len(decomp_result['outlier_indices']) > 0:
                outlier_dates = kpi_data.iloc[decomp_result['outlier_indices']]['REPORT_TIME']
                outlier_residuals = decomp_result['resid'][decomp_result['outlier_indices']]
                
                fig.add_trace(
                    go.Scatter(x=to_plotly_list(outlier_dates), y=to_plotly_list(outlier_residuals),
                              mode='markers', name='ç•°å¸¸é»',
                              marker=dict(color='red', size=8, symbol='x')),
                    row=4, col=1
                )
            
            # Add threshold lines to residual plot
            residual_std = np.std(decomp_result['resid'])
            residual_mean = np.mean(decomp_result['resid'])
            
            fig.add_hline(y=to_plotly_list(residual_mean + threshold * residual_std), 
                         line_dash="dash", line_color="red", row=4, col=1)
            fig.add_hline(y=to_plotly_list(residual_mean - threshold * residual_std), 
                         line_dash="dash", line_color="red", row=4, col=1)
            
            fig.update_layout(height=800, showlegend=False)
            fig.update_xaxes(title_text="æ™‚é–“", row=4, col=1)
            
            st.plotly_chart(fig)
            
            # Show reconstructed vs original
            st.subheader("ğŸ“ˆ é‡å»ºæ•¸æ“šèˆ‡ç•°å¸¸é»")
            
            fig2 = go.Figure()
            
            # Add original data
            fig2.add_trace(go.Scatter(
                x=to_plotly_list(kpi_data['REPORT_TIME']), y=to_plotly_list(kpi_data['VALUE']),
                mode='lines+markers',
                name='åŸå§‹æ•¸æ“š',
                line=dict(color='blue', width=2),
                marker=dict(size=4)
            ))
            
            # Add reconstructed data (trend + seasonal)
            reconstructed = decomp_result['trend'] + decomp_result['seasonal']
            fig2.add_trace(go.Scatter(
                x=to_plotly_list(kpi_data['REPORT_TIME']), y=to_plotly_list(reconstructed),
                mode='lines',
                name='é‡å»ºæ•¸æ“š (è¶¨å‹¢+å­£ç¯€æ€§)',
                line=dict(color='green', width=2, dash='dash')
            ))
            
            # Add outliers
            if len(decomp_result['outlier_indices']) > 0:
                outlier_dates = kpi_data.iloc[decomp_result['outlier_indices']]['REPORT_TIME']
                outlier_values = kpi_data.iloc[decomp_result['outlier_indices']]['VALUE']
                
                fig2.add_trace(go.Scatter(
                    x=to_plotly_list(outlier_dates), y=to_plotly_list(outlier_values),
                    mode='markers',
                    name='ç•°å¸¸é»',
                    marker=dict(color='red', size=10, symbol='x')
                ))
            
            fig2.update_layout(
                title=f"{selected_fab} - {selected_kpi} - å­£ç¯€æ€§åˆ†è§£ç•°å¸¸åµæ¸¬",
                xaxis_title="å ±å‘Šæ™‚é–“",
                yaxis_title="æ•¸å€¼",
                hovermode='x unified',
                height=500
            )
            
            st.plotly_chart(fig2)
            
            # Show statistics
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("ç¸½æ•¸æ“šé»", len(kpi_data))
            
            with col2:
                st.metric("ç•°å¸¸é»æ•¸é‡", len(decomp_result['outlier_indices']))
            
            with col3:
                anomaly_rate = len(decomp_result['outlier_indices']) / len(kpi_data) * 100
                st.metric("ç•°å¸¸ç‡", f"{anomaly_rate:.2f}%")
            
            # Show outlier details
            if len(decomp_result['outlier_indices']) > 0:
                st.subheader("ğŸ” ç•°å¸¸é»è©³ç´°è³‡è¨Š")
                
                outlier_df = kpi_data.iloc[decomp_result['outlier_indices']].copy()
                outlier_df['è¶¨å‹¢å€¼'] = decomp_result['trend'][decomp_result['outlier_indices']]
                outlier_df['å­£ç¯€æ€§å€¼'] = decomp_result['seasonal'][decomp_result['outlier_indices']]
                outlier_df['æ®˜å·®å€¼'] = decomp_result['resid'][decomp_result['outlier_indices']]
                outlier_df['é‡å»ºå€¼'] = decomp_result['trend'][decomp_result['outlier_indices']] + decomp_result['seasonal'][decomp_result['outlier_indices']]
                outlier_df = outlier_df.sort_values('æ®˜å·®å€¼', key=to_plotly_list(abs), ascending=False)
                
                st.dataframe(outlier_df[['REPORT_TIME', 'VALUE', 'è¶¨å‹¢å€¼', 'å­£ç¯€æ€§å€¼', 'æ®˜å·®å€¼', 'é‡å»ºå€¼']])
            else:
                st.success("âœ… æœªç™¼ç¾ç•°å¸¸é»")
                
        except Exception as e:
            st.error(f"âŒ å­£ç¯€æ€§åˆ†è§£éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            st.info("ğŸ’¡ å»ºè­°ï¼š1) ç¢ºä¿æ•¸æ“šæœ‰è¶³å¤ çš„é€±æœŸæ€§ 2) èª¿æ•´å­£ç¯€é€±æœŸåƒæ•¸ 3) æª¢æŸ¥æ•¸æ“šæ˜¯å¦æœ‰ç¼ºå¤±å€¼")

def perform_seasonal_decomposition_fab(kpi_data, model, period, threshold):
    """é©ç”¨æ–¼ FAB è³‡æ–™çµæ§‹çš„å­£ç¯€æ€§åˆ†è§£"""
    try:
        from statsmodels.tsa.seasonal import seasonal_decompose
    except ImportError:
        st.error("âŒ éœ€è¦å®‰è£ statsmodels åº«: pip install statsmodels")
        return None
    
    data = kpi_data['VALUE'].values
    
    # Check if we have enough data points
    if len(data) < 2 * period:
        return None
    
    try:
        # Perform seasonal decomposition
        decomposition = seasonal_decompose(data, model=model, period=period, extrapolate_trend='freq')
        
        # Extract components
        trend = decomposition.trend
        seasonal = decomposition.seasonal
        resid = decomposition.resid
        
        # Remove NaN values
        valid_mask = ~np.isnan(resid)
        resid_clean = resid[valid_mask]
        
        # Detect outliers in residuals
        residual_mean = np.mean(resid_clean)
        residual_std = np.std(resid_clean)
        
        outlier_mask = np.abs(resid - residual_mean) > threshold * residual_std
        outlier_mask = outlier_mask & valid_mask
        
        outlier_indices = np.where(outlier_mask)[0]
        
        return {
            'trend': trend,
            'seasonal': seasonal,
            'resid': resid,
            'outlier_indices': outlier_indices,
            'residual_mean': residual_mean,
            'residual_std': residual_std
        }
        
    except Exception as e:
        st.error(f"åˆ†è§£éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return None

def perform_seasonal_decomposition(df, kpi_column, date_column, model, period, threshold):
    try:
        from statsmodels.tsa.seasonal import seasonal_decompose
    except ImportError:
        st.error("âŒ éœ€è¦å®‰è£ statsmodels åº«: pip install statsmodels")
        return None
    
    data = df[kpi_column].values
    
    # Check if we have enough data points
    if len(data) < 2 * period:
        return None
    
    try:
        # Perform seasonal decomposition
        decomposition = seasonal_decompose(data, model=model, period=period, extrapolate_trend='freq')
        
        # Extract components
        trend = decomposition.trend
        seasonal = decomposition.seasonal
        resid = decomposition.resid
        
        # Remove NaN values
        valid_mask = ~np.isnan(resid)
        resid_clean = resid[valid_mask]
        
        # Detect outliers in residuals
        residual_mean = np.mean(resid_clean)
        residual_std = np.std(resid_clean)
        
        outlier_mask = np.abs(resid - residual_mean) > threshold * residual_std
        outlier_mask = outlier_mask & valid_mask
        
        outlier_indices = np.where(outlier_mask)[0]
        
        return {
            'trend': trend,
            'seasonal': seasonal,
            'resid': resid,
            'outlier_indices': outlier_indices,
            'residual_mean': residual_mean,
            'residual_std': residual_std
        }
        
    except Exception as e:
        st.error(f"åˆ†è§£éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return None

if __name__ == "__main__":
    main()